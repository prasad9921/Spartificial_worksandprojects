{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"Assignment_5_AI4LR_Final.ipynb","provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# <center> Assignment 5 (AI4LR)"],"metadata":{"id":"elcpXOswLRgc"}},{"cell_type":"code","source":["Your_Name = \" \"\n","Your_Email_id = \" \""],"metadata":{"id":"cfmCfF7eiTpk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Open this notebook in kaggle for easy access to the dataset and related libraries. "],"metadata":{"id":"juQiIIMl4qVz"}},{"cell_type":"code","source":["# importing libraries\n","import tensorflow as tf\n","import keras\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import cv2\n","from PIL import Image"],"metadata":{"id":"f5ayJkkRwkjb","execution":{"iopub.status.busy":"2022-03-27T06:41:52.761932Z","iopub.execute_input":"2022-03-27T06:41:52.762222Z","iopub.status.idle":"2022-03-27T06:41:52.767773Z","shell.execute_reply.started":"2022-03-27T06:41:52.762191Z","shell.execute_reply":"2022-03-27T06:41:52.766709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data \n","\n","To get the dataset for this assignment, got to Add data option and search for https://www.kaggle.com/datasets/datatangai/people-with-occlusion-and-multipose-face-data in Search URL field.\n","\n","Import this dataset and there is only one image in this dataset. We are going to use this image only. "],"metadata":{"id":"d72b-W8fFaKI"}},{"cell_type":"code","source":["img_path = \"../input/people-with-occlusion-and-multipose-face-data/3.png\"\n","\n","img = Image.open(img_path)\n","\n","img"],"metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:39:31.673784Z","iopub.execute_input":"2022-03-27T06:39:31.674039Z","iopub.status.idle":"2022-03-27T06:39:33.209950Z","shell.execute_reply.started":"2022-03-27T06:39:31.673999Z","shell.execute_reply":"2022-03-27T06:39:33.208877Z"},"trusted":true,"id":"T808--eV4qV0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q1 (1 Point) \n","\n","Convert the images \"img\" into an array and store that array into 'img_arr' variable.\n","\n","Plot the img_arr using plt\n"],"metadata":{"id":"QAhrBKqmjuHB"}},{"cell_type":"code","source":["# Complete the following code\n","\n","\n","img_arr = \n","\n","\n","# plot img_arr\n","\n"],"metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:01:23.807293Z","iopub.execute_input":"2022-02-01T15:01:23.807846Z","iopub.status.idle":"2022-02-01T15:01:24.294027Z","shell.execute_reply.started":"2022-02-01T15:01:23.807802Z","shell.execute_reply":"2022-02-01T15:01:24.293337Z"},"id":"ShSSOgg350kW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q2 (2 Points)\n","Run the below code.\n","\n","Do you see anything abnormal with the shape of the above image? If yes, state the reason. "],"metadata":{"id":"KqNymgaxpk1i"}},{"cell_type":"code","source":["print(\"Image shape:\", img_arr.shape)\n","\n","## print your reason here\n","\n","reason = \"\"\n","\n","print(reason)"],"metadata":{"id":"23zzRR39pj-X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q3 (6 Points)\n","The above image \"img_arr\" is a combination of ten different images, separate all ten images using numpy and show all of them using plt.subplot.\n","\n","(the size and shape of individual images should remain the same)"],"metadata":{"id":"0wj839JEq2vN"}},{"cell_type":"code","source":["# first we are converting our four channels image into three channels image (easy to use and no extra complexities)\n","'''Do not make any change in this below line of code.'''\n","img_arr = img_arr[:, :, :3]\n","\n","\n","# Write your code here--------------------------->\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"G979ANNupyoY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q4 (2 Points)\n","imgGray = ** 0.2989 * R + 0.5870 * G + 0.1140 * B **. \n","\n","this is the formula to convert any colored images to greyscale. \n","\n","\n","Convert \"first\" into greyscale using above formula and store it in \"first_bw\""],"metadata":{"id":"wYxLSwSWrgey"}},{"cell_type":"code","source":["first = img_arr[:500, :290, :]\n","\n","plt.figure(figsize = (5,10))\n","plt.imshow(first)\n","plt.show()\n","\n","\n","\n","## Write your code here\n","\n","first_bw = "],"metadata":{"id":"482aUQZeraMd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q5 (6 Points)\n","Find out the effects of kernel1 and kernel2 on the \"first\" using cv2.filter2D function. \n","\n","Plot and State the difference between effect1 and effect2.\n"],"metadata":{"id":"kiStl1oc6O5O"}},{"cell_type":"code","source":["kernel1 = np.array([[-1,-1,-1],\n","                    [0,0,0],\n","                    [1,1,1]])\n","\n","kernel2 = kernel1.transpose()\n","\n","\n","effect1 = cv2.filter2D(src = first, kernel = kernel1, ddepth = -1)\n","effect2 = cv2.filter2D(src = first, kernel = kernel2, ddepth = -1)\n","\n","# plot effect1 and effect2 using plt.subplots\n","\n","\n","\n","\n","# state the difference\n","\n","difference = \"\"\n","\n","print(difference)\n"],"metadata":{"id":"TbY77UkX67Xv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q6 (4 Points)\n","\n","State differences between -  \n","\n","> Feature extraction and finetuning in transfer learning.\n","\n","> Hidden layer in a neural network and Head layer in transfer learning "],"metadata":{"id":"Qh-Tu3DrGf7Y"}},{"cell_type":"code","source":["# start your answer here\n","\n","answer1 = \n","\n","\n","answer2 = \n","\n","print(answer1)\n","print()\n","print(answer2)\n"],"metadata":{"id":"R1ja-IvR4d34","execution":{"iopub.status.busy":"2022-03-27T06:53:25.854334Z","iopub.execute_input":"2022-03-27T06:53:25.854647Z","iopub.status.idle":"2022-03-27T06:53:25.860818Z","shell.execute_reply.started":"2022-03-27T06:53:25.854591Z","shell.execute_reply":"2022-03-27T06:53:25.859658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q7 (1 point)\n","\n","Write the formula for IOU score using numpy."],"metadata":{"id":"s7S2hsT-7eu-"}},{"cell_type":"code","source":["# Print your answer \n","\n","formula ="],"metadata":{"id":"_qcETSSR8866"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"7UXaXUjhhCvz"}},{"cell_type":"markdown","source":["## Q8 (3 points)\n","\n","For below model, \n","\n","For a Convolutional layer in neural network, below values are given\n","\n","> Input shape = (64, 64, 3)\n","\n","> Convolutional filter size = (3,3)\n","\n","> Number of Conv Filters = 16\n","\n","> padding = \"same\"\n","\n","> stride = 1\n","\n","\n","Find out the **output shape** after this layer, **number of total trainable paramaters** and **computational cost**.\n","\n","Hint: Total trainable parameters is the sum of total number of weights and biases in the layer.\n","\n","Hint: Computational cost is the total number of matrix multiplications"],"metadata":{"id":"0mL9NMduQFg5"}},{"cell_type":"code","source":["from keras.engine.sequential import Sequential\n","from keras.layers import Input, Conv2D, Dense, MaxPooling2D, Dropout\n","\n","model = Sequential([\n","                    Input(shape = (500, 290, 3)),\n","                    Conv2D(16, (3,3), activation = 'relu'),\n","                    MaxPooling2D(2,2),\n","                    Conv2D(32, (3,3), activation = 'relu'),\n","                    MaxPooling2D(2,2),\n","                    Conv2D(64, (3,3), activation = 'relu'),\n","                    MaxPooling2D(2,2),\n","                    Dense(256, activation = \"relu\"),\n","                    Dropout(0.5),\n","                    Dense(5, activation = \"sigmoid\")\n","])\n","\n","# write your answer here\n","\n","out_shape = \n","\n","train_params = \n","\n","comp_cost = # write a function for this looping over layers, calculating for each layer\n","\n","print(\"Output shape:\", out_shape)\n","print(\"Trainable parameters:\", train_params)\n","print(\"Computational Cost:\", comp_cost)"],"metadata":{"id":"HUVQCUDXP_Rm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q9 (5 points)\n","\n","1. Write down the name of the model that used dropout for preventing overfitting for the first time?\n","\n","2. How did GoogleNet manage to reduce its number of parameters despite having a deep heirarchy of conv layers?\n","\n","3. Which network made 3-by-3 filters state-of-the-art?\n","\n","4. How does VGGNet ensure growing depth despit shrinking spatial dimensions deep into the network hierarchy?\n","\n","5. What does Deconvnet do? Which network introduced it? "],"metadata":{"id":"1gL2_7F2jxec"}},{"cell_type":"markdown","source":["## Q10 (20 points)\n","\n","Use the Iris dataset to classify iris flowers into three classes of species.\n","https://www.kaggle.com/datasets/uciml/iris \n","\n","Develop a transfer learning network by following these steps:\n","1. Derive a base model using VGGNet - any configuration of your choice. \n","\n","2. Augment your data set by defining data augmentation layers - use at least 2 different augmentation techniques.\n","\n","3. Build your network with the augmentation layers and the base model from VGGNet.\n","\n","4. Add a pooling layer and a dense layer at the end to get a single prediction per image.\n","\n","5. Compile your model using categorical cross entropy loss, adam optimizer, and accuracy metric.\n","\n","6. Train your network twice - once with dropout and another time without dropout. \n","\n","7. Plot training and validation losses and accuracies for both cases of point #6. \n"],"metadata":{"id":"wJMt9xKSTQsf"}},{"cell_type":"markdown","source":["## Thank you for completing all the questions!\n","#### Download your notebook and submit it in the google form"],"metadata":{"id":"wIiqmkDHRLwC"}},{"cell_type":"code","source":[""],"metadata":{"id":"whmuWZ5AlMzL"},"execution_count":null,"outputs":[]}]}