{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> Best Practices for Image segmentation (W7S2)","metadata":{"id":"kD6lbSNVLszk"}},{"cell_type":"markdown","source":"#### This session will provide you brief introduction to some best practices to improve performance of your Image segmentation model","metadata":{"id":"pHL8t-2oLszp"}},{"cell_type":"code","source":"import numpy as np\nimport os","metadata":{"id":"3eItJm1hLszr","execution":{"iopub.status.busy":"2022-04-12T19:11:07.824536Z","iopub.execute_input":"2022-04-12T19:11:07.824941Z","iopub.status.idle":"2022-04-12T19:11:07.850726Z","shell.execute_reply.started":"2022-04-12T19:11:07.824845Z","shell.execute_reply":"2022-04-12T19:11:07.849574Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"'''\nHere load_data function is called. This will load the dataset paths and \nsplit it into X_train, X_test, y_train, y_test '''\n\nimg_dir = '../input/artificial-lunar-rocky-landscape-dataset/images/render'\nmask_dir = '../input/artificial-lunar-rocky-landscape-dataset/images/clean'\n\n\n# let's get the list of image paths and mask paths in sorted order from the given directory respectively\nimages = [os.path.join(img_dir, x) for x in sorted(os.listdir(img_dir))]\nmasks = [os.path.join(mask_dir, x) for x in sorted(os.listdir(mask_dir))]\n","metadata":{"id":"ofv9tYqEkO5V","execution":{"iopub.status.busy":"2022-04-12T12:20:09.237775Z","iopub.execute_input":"2022-04-12T12:20:09.238021Z","iopub.status.idle":"2022-04-12T12:20:10.772964Z","shell.execute_reply.started":"2022-04-12T12:20:09.237990Z","shell.execute_reply":"2022-04-12T12:20:10.771996Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"s_path = images[0]\n\nsample = imread(s_path)\n\nplt.imshow(sample)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:47:25.047448Z","iopub.execute_input":"2022-04-12T12:47:25.047769Z","iopub.status.idle":"2022-04-12T12:47:25.322635Z","shell.execute_reply.started":"2022-04-12T12:47:25.047733Z","shell.execute_reply":"2022-04-12T12:47:25.321867Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Difference of Gaussians\n\nhttps://scikit-image.org/docs/dev/api/skimage.filters.html?highlight=gaussian#difference-of-gaussians","metadata":{}},{"cell_type":"code","source":"import skimage\n\n# Find features between low_sigma and high_sigma in size.\npre = skimage.filters.difference_of_gaussians(sample, low_sigma = 2, high_sigma = 8)\n\nplt.imshow(pre)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:41:40.174271Z","iopub.execute_input":"2022-04-12T12:41:40.174607Z","iopub.status.idle":"2022-04-12T12:41:40.655001Z","shell.execute_reply.started":"2022-04-12T12:41:40.174573Z","shell.execute_reply":"2022-04-12T12:41:40.653791Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Ensure that all the images have the same orientation","metadata":{}},{"cell_type":"code","source":"import albumentations as A\nimport cv2\n\n# Declare an augmentation pipeline\ntransform = A.Compose([\n    A.RandomCrop(width=256, height=256),\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(p=0.2),\n])\n\n# Read an image with OpenCV and convert it to the RGB colorspace\nimage = cv2.imread(s_path)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# Augment an image\ntransformed = transform(image=image)\ntransformed_image = transformed[\"image\"]\n\nplt.imshow(transformed_image)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:47:59.390000Z","iopub.execute_input":"2022-04-12T12:47:59.390448Z","iopub.status.idle":"2022-04-12T12:47:59.644570Z","shell.execute_reply.started":"2022-04-12T12:47:59.390413Z","shell.execute_reply":"2022-04-12T12:47:59.643721Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Why Albumentations?\n\nhttps://github.com/albumentations-team/albumentations\n\n* Albumentations supports all common computer vision tasks such as classification, semantic segmentation, instance segmentation, object detection, and pose estimation.\n* The library provides a simple unified API to work with all data types: images (RBG-images, grayscale images, multispectral images), segmentation masks, bounding boxes, and keypoints.\n*     The library contains more than 70 different augmentations to generate new training samples from the existing data.\n*     Albumentations is fast. We benchmark each new release to ensure that augmentations provide maximum speed.\n*     It works with popular deep learning frameworks such as PyTorch and TensorFlow. By the way, Albumentations is a part of the PyTorch ecosystem.\n*     Written by experts. The authors have experience both working on production computer vision systems and participating in competitive machine learning. Many core team members are Kaggle Masters and Grandmasters.\n*     The library is widely used in industry, deep learning research, machine learning competitions, and open source projects.\n","metadata":{}},{"cell_type":"markdown","source":"## Contrast Streching and Histogram Equalization","metadata":{}},{"cell_type":"code","source":"# Contrast stretching\np2, p98 = np.percentile(sample, (2, 98))\nimg_rescale = skimage.exposure.rescale_intensity(sample, in_range=(p2, p98))\n\n# Equalization\nimg_eq = skimage.exposure.equalize_hist(sample)\n\n# plotting\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (20, 8))\n\nax1.set_title(\"Original\")\nax1.imshow(sample)\n\nax2.set_title(\"Contrast streching\")\nax2.imshow(img_rescale)\n\nax3.set_title(\"Histogram Equalization\")\nax3.imshow(img_eq)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:04:50.392202Z","iopub.execute_input":"2022-04-12T13:04:50.392531Z","iopub.status.idle":"2022-04-12T13:04:51.091541Z","shell.execute_reply.started":"2022-04-12T13:04:50.392496Z","shell.execute_reply":"2022-04-12T13:04:51.090720Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"While histogram equalization has the advantage that it requires no parameters, it sometimes yields unnatural looking images.\n\nIn Contrast stretching, the image is rescaled to include all intensities that fall within the 2nd and 98th percentiles.|","metadata":{}},{"cell_type":"markdown","source":"## Pseudo labeling (Semi Supervised learning)\n\nhttps://towardsdatascience.com/pseudo-labeling-to-deal-with-small-datasets-what-why-how-fd6f903213af\n\nIt will be useful in those cases when you have labels for a very small subset of data but not for the other. In that case, you can generate model training pipeline to use outputs from model unlabeled data to act as labels and train with unlabeled data also.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/1118/1*Yk_mGPVIJgkIhf0gWo7PTA.png)","metadata":{}},{"cell_type":"markdown","source":"## Ensemble with different SOTA models. \n\nhttps://www.kaggle.com/c/inclusive-images-challenge/discussion/72450\n\nhttps://github.com/IVPLatNU/DeepCovidXR\n\n![](https://miro.medium.com/max/1400/1*MxD8Kn_Rn9p_Au4MOGgsmg.png)\n","metadata":{}},{"cell_type":"markdown","source":"## Different metrics to use:-\n\nhttps://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2","metadata":{}},{"cell_type":"markdown","source":"## Some more references for future:-\n\n* https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0255397\n* https://neptune.ai/blog/image-segmentation\n* https://www.v7labs.com/blog/panoptic-segmentation-guide\n* https://www.v7labs.com/blog/image-annotation-guide\n* And always: https://spartificial.com/resources\n","metadata":{}},{"cell_type":"markdown","source":"# <center> And by the way have you seen convolved foxes before? :)","metadata":{}},{"cell_type":"markdown","source":"![](https://raw.githubusercontent.com/vecxoz/kag18_inclusive_images/master/explore/6edc75f64a451387.jpg)","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"3ajAnaiZkO5m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"q26M3dwpkO5n"},"execution_count":null,"outputs":[]}]}