{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xksEYwr8QXgN"
   },
   "source": [
    "# <center>Assignment 6 [Final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T15:05:09.338168Z",
     "iopub.status.busy": "2022-06-12T15:05:09.337149Z",
     "iopub.status.idle": "2022-06-12T15:05:09.367805Z",
     "shell.execute_reply": "2022-06-12T15:05:09.366976Z",
     "shell.execute_reply.started": "2022-06-12T15:05:09.338080Z"
    },
    "id": "2WVqrOVwm8yz"
   },
   "outputs": [],
   "source": [
    "Your_name = \"V N D S R Prasad Jettiboina\"\n",
    "Your_emailid = \"prasadjv99@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qWKqzF4415S"
   },
   "source": [
    "### **NOTE: Open this notebook in kaggle and import Artificial Lunar Landscape Dataset.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rb3HM3Asm8y1"
   },
   "source": [
    "## > If you run this notebook as it is, you will get the val_iou_score of around 0.20 (remember to use GPU for training the model)\n",
    "\n",
    "## > Your goal is to increase the val_iou_score as much as you can for this project using any method. The evaluation of this assignment will be based on your acquired val_iou_score. One point for each increasing 0.01 val_iou_score. \n",
    "\n",
    "> For example - if val_iou_score = 0.41, your points will be 41/100. \n",
    "\n",
    "## > Please check your notebook before submission, try to avoid any error.\n",
    "\n",
    "### Some tips to increase the performance\n",
    "* Increase the number of epochs\n",
    "* Increase the number of layers in your model\n",
    "* Using SOTA high performance networks with transfer learning\n",
    "* Using callbacks and carefully observing your model performance\n",
    "\n",
    "You are free to use other techniques too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSjKJ2JQtLV9"
   },
   "source": [
    "# GUIDELINES ABOUT MAKING CHANGES TO THIS NOTEBOOK\n",
    "\n",
    "For every change you make to this notebook, only those supported by the following would be considered for evaluation:\n",
    "\n",
    "1. A descriptive comment explaining the change, e.g., if you are adding an extra conv2d layer, write about all the aspects of the conv2d layer you are adding. The comment should be placed at the point where the layer will be added. \n",
    "\n",
    "2. Changes brought to the system because of changes you introduced, e.g., if you changed layers - added, deleted, etc., you MUST show model properties before and after the changes were made.\n",
    "\n",
    "3. Data preprocessing changes - if you use new data preprocessing techniques that are not a part of this notebook, you MUST explain their inner workings using 2-3 MARKDOWN cells, and ONLY AFTER THAT,  proceed to use that technique. Without this explanation, your technique will not be considered for evaluation.\n",
    "\n",
    "4. ALL improvements MUST BE REPORTED VIA PLOTS OR TABLES OR BOTH, e.g., if increasing epochs from 30 to 50 improved your results, but decreasing learning_rate from 0.0001 to 0.00005 also improved your results, then these gains FIRST HAVE TO BE REPORTED SEPARATELY VIA PLOTS, THEN AGAIN TOGETHER VIA TABLES. \n",
    "\n",
    "  One plot can show iou values increasing from epoch 30 to epoch 50. Another plot can show iou values improving at varying learning rates. Finally tables can be used to show iou values for different learning rates, table 1 for lr_1 shows iou for epochs 30 through 50, table 2 for lr_2 shows iou for epochs 30 through 50, and so on and so forth - ALL YOUR RESULTS MUST BE COMPULSORILY QUANTIFIABLE! \n",
    "\n",
    "It is therefore advised to work on one improvement, optimize it, plot it, document it, then proceed to the next improvement - till you get a satisfactory IOU score.\n",
    "\n",
    "5. FINAL IMPROVEMENT SUMMARY TABLE: Prepare a table with columns (improv#, description, increase in iou from, increase in iou to), and list out all the improvements you made to improve your model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:44:31.925624Z",
     "iopub.status.busy": "2022-06-12T16:44:31.925159Z",
     "iopub.status.idle": "2022-06-12T16:44:47.491454Z",
     "shell.execute_reply": "2022-06-12T16:44:47.490135Z",
     "shell.execute_reply.started": "2022-06-12T16:44:31.925576Z"
    },
    "id": "HRJUKjN1QXgS"
   },
   "outputs": [],
   "source": [
    "!pip install segmentation_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:44:47.495376Z",
     "iopub.status.busy": "2022-06-12T16:44:47.494856Z",
     "iopub.status.idle": "2022-06-12T16:44:55.073767Z",
     "shell.execute_reply": "2022-06-12T16:44:55.072713Z",
     "shell.execute_reply.started": "2022-06-12T16:44:47.495329Z"
    },
    "id": "bGIcq3_DQXgT"
   },
   "outputs": [],
   "source": [
    "# import the necessary Library\n",
    "\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import keras \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIJMgWvKm8y7"
   },
   "source": [
    "* Provide environment variable SM_FRAMEWORK=keras / SM_FRAMEWORK=tf.keras before import segmentation_models\n",
    "* Change framework sm.set_framework('keras') / sm.set_framework('tf.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:44:55.076223Z",
     "iopub.status.busy": "2022-06-12T16:44:55.075332Z",
     "iopub.status.idle": "2022-06-12T16:44:55.465123Z",
     "shell.execute_reply": "2022-06-12T16:44:55.464110Z",
     "shell.execute_reply.started": "2022-06-12T16:44:55.076179Z"
    },
    "id": "x2HKIVofm8y7"
   },
   "outputs": [],
   "source": [
    "# Setting framework environment\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "sm.set_framework('tf.keras')\n",
    "keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdS9NTtwQXgV"
   },
   "source": [
    "## Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:44:55.468003Z",
     "iopub.status.busy": "2022-06-12T16:44:55.467511Z",
     "iopub.status.idle": "2022-06-12T16:44:55.486013Z",
     "shell.execute_reply": "2022-06-12T16:44:55.484837Z",
     "shell.execute_reply.started": "2022-06-12T16:44:55.467955Z"
    },
    "id": "EQGsLbOVQXgW"
   },
   "outputs": [],
   "source": [
    "H = 256 # height of image\n",
    "W = 256 # width of image\n",
    "\n",
    "'''This function is used to return the list of path for images and masks in\n",
    "sorted order from the given directory respectively.'''\n",
    "# function to return list of image paths and mask paths \n",
    "def process_data(IMG_DIR, MASK_DIR):\n",
    "    images = [os.path.join(IMG_DIR, x) for x in sorted(os.listdir(IMG_DIR))]\n",
    "    masks = [os.path.join(MASK_DIR, x) for x in sorted(os.listdir(MASK_DIR))]\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "'''This function is used to return splitted list of images and corresponding \n",
    "mask paths in train and test by providing test size.'''\n",
    "# function to load data and train test split\n",
    "def load_data(IMG_DIR, MASK_DIR):\n",
    "    X, y = process_data(IMG_DIR, MASK_DIR)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "'''This function is used to read images. It takes image path as input. \n",
    "After reading image it is resized by width and height provide above(256 x 256). \n",
    "Next normalization is done by dividing each values with 255. And the result is returned.'''\n",
    "# function to read image\n",
    "def read_image(x):\n",
    "    x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (W, H))\n",
    "    x = x / 255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "\n",
    "'''This function is used to read masks.'''\n",
    "# function to read mask\n",
    "def read_mask(x):\n",
    "    x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (W, H))\n",
    "    x = x.astype(np.int32)\n",
    "    return x\n",
    "\n",
    "'''This function is used to generate tensorflow data pipeline. \n",
    "The tensorflow data pipeline is mapped to function ‘preprocess’ .'''\n",
    "# function for tensorflow dataset pipeline\n",
    "def tf_dataset(x, y, batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.shuffle(buffer_size=5000)\n",
    "    dataset = dataset.map(preprocess)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.prefetch(2)\n",
    "    return dataset\n",
    "\n",
    "'''This function takes image and mask path. \n",
    "It reads the image and mask as provided by paths. \n",
    "Mask is one hot encoded for multi class segmentation (here 4 class).'''\n",
    "# function to read image and mask amd create one hot encoding for mask\n",
    "def preprocess(x, y):\n",
    "    def f(x, y):\n",
    "        x = x.decode()\n",
    "        y = y.decode()\n",
    "\n",
    "        image = read_image(x)\n",
    "        mask = read_mask(y)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.int32])\n",
    "    mask = tf.one_hot(mask, 4, dtype=tf.int32)\n",
    "    image.set_shape([H, W, 3])\n",
    "    mask.set_shape([H, W, 4])\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufOlyg7MQXgY"
   },
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:44:55.488919Z",
     "iopub.status.busy": "2022-06-12T16:44:55.487604Z",
     "iopub.status.idle": "2022-06-12T16:44:56.027090Z",
     "shell.execute_reply": "2022-06-12T16:44:56.025935Z",
     "shell.execute_reply.started": "2022-06-12T16:44:55.488871Z"
    },
    "id": "vHWstFNTQXgY"
   },
   "outputs": [],
   "source": [
    "'''RENDER_IMAGE_DIR_PATH: ‘Path of image directory’\n",
    "GROUND_MASK_DIR_PATH: ‘Path of mask directory’\n",
    "\n",
    "Here load_data function is called. This will load the dataset paths and \n",
    "split it into X_train, X_test, y_train, y_test '''\n",
    "\n",
    "RENDER_IMAGE_DIR_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/render'\n",
    "GROUND_MASK_DIR_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/clean'\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data(RENDER_IMAGE_DIR_PATH, GROUND_MASK_DIR_PATH)\n",
    "print(f\"Dataset:\\n Train: {len(X_train)} \\n Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfSTVsjCQXgZ"
   },
   "source": [
    "## Generate tensorflow data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T15:05:29.472514Z",
     "iopub.status.busy": "2022-06-12T15:05:29.471977Z",
     "iopub.status.idle": "2022-06-12T15:05:32.557745Z",
     "shell.execute_reply": "2022-06-12T15:05:32.556845Z",
     "shell.execute_reply.started": "2022-06-12T15:05:29.472475Z"
    },
    "id": "4xsJKtW0QXgZ"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "'''Here the tf_dataset function is called will generate the tensorflow data pipeline.'''\n",
    "# calling tf_dataset\n",
    "train_dataset = tf_dataset(X_train, y_train, batch=batch_size)\n",
    "valid_dataset = tf_dataset(X_test, y_test, batch=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MqxtDTmQXga"
   },
   "source": [
    "## Creating U-net Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T15:05:32.559938Z",
     "iopub.status.busy": "2022-06-12T15:05:32.559360Z",
     "iopub.status.idle": "2022-06-12T15:05:32.577195Z",
     "shell.execute_reply": "2022-06-12T15:05:32.576139Z",
     "shell.execute_reply.started": "2022-06-12T15:05:32.559898Z"
    },
    "id": "tYCyf8smQXga"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "'''conv_block it is used to create one block with two convolution layer \n",
    "followed by BatchNormalization and activation function relu. \n",
    "If the pooling is required then Maxpool2D is applied and return it else not.'''\n",
    "# function to create convolution block\n",
    "def conv_block(inputs, filters, pool=True):\n",
    "    x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    if pool == True:\n",
    "        p = MaxPool2D((2, 2))(x)\n",
    "        return x, p\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "'''build_unet it is used to create the U-net architecture.'''\n",
    "# function to build U-net\n",
    "def build_unet(shape, num_classes):\n",
    "    inputs = Input(shape)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    x1, p1 = conv_block(inputs, 16, pool=True)\n",
    "    x2, p2 = conv_block(p1, 32, pool=True)\n",
    "    x3, p3 = conv_block(p2, 48, pool=True)\n",
    "    x4, p4 = conv_block(p3, 64, pool=True)\n",
    "\n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = conv_block(p4, 128, pool=False)\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    u1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(b1)\n",
    "    c1 = Concatenate()([u1, x4])\n",
    "    x5 = conv_block(c1, 64, pool=False)\n",
    "\n",
    "    u2 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x5)\n",
    "    c2 = Concatenate()([u2, x3])\n",
    "    x6 = conv_block(c2, 48, pool=False)\n",
    "\n",
    "    u3 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x6)\n",
    "    c3 = Concatenate()([u3, x2])\n",
    "    x7 = conv_block(c3, 32, pool=False)\n",
    "\n",
    "    u4 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x7)\n",
    "    c4 = Concatenate()([u4, x1])\n",
    "    x8 = conv_block(c4, 16, pool=False)\n",
    "\n",
    "    \"\"\" Output layer \"\"\"\n",
    "    output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x8)\n",
    "\n",
    "    return Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T15:05:32.579188Z",
     "iopub.status.busy": "2022-06-12T15:05:32.578752Z",
     "iopub.status.idle": "2022-06-12T15:05:33.012256Z",
     "shell.execute_reply": "2022-06-12T15:05:33.011359Z",
     "shell.execute_reply.started": "2022-06-12T15:05:32.579151Z"
    },
    "id": "65hPnreJQXgb"
   },
   "outputs": [],
   "source": [
    "# calling build_unet function\n",
    "model = build_unet((256, 256, 3), 4)\n",
    "\n",
    "#printing model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMgeqmX2QXgc"
   },
   "source": [
    "## Load model and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T15:05:33.014451Z",
     "iopub.status.busy": "2022-06-12T15:05:33.013828Z",
     "iopub.status.idle": "2022-06-12T15:05:33.387288Z",
     "shell.execute_reply": "2022-06-12T15:05:33.386429Z",
     "shell.execute_reply.started": "2022-06-12T15:05:33.014408Z"
    },
    "id": "z91qV2ZwQXgc"
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from segmentation_models.metrics import iou_score\n",
    "import datetime, os\n",
    "\n",
    "\"\"\" Defining Hyperparameters \"\"\"\n",
    "img_shape = (256, 256, 3)\n",
    "num_classes = 4\n",
    "lr = 1e-4\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "\n",
    "\"\"\" Model building and compiling \"\"\"\n",
    "model = build_unet(img_shape, num_classes)\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=tf.keras.optimizers.Adam(lr), \n",
    "              metrics=[iou_score])\n",
    "\n",
    "\n",
    "train_steps = len(X_train)//batch_size\n",
    "valid_steps = len(X_test)//batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBhRPBKPQXgc"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T15:05:33.391186Z",
     "iopub.status.busy": "2022-06-12T15:05:33.390674Z",
     "iopub.status.idle": "2022-06-12T15:14:57.517518Z",
     "shell.execute_reply": "2022-06-12T15:14:57.516611Z",
     "shell.execute_reply.started": "2022-06-12T15:05:33.391141Z"
    },
    "id": "4lJgBNVwQXgd"
   },
   "outputs": [],
   "source": [
    "'''model.fit is used to train the model'''\n",
    "model_history = model.fit(train_dataset,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_data=valid_dataset,\n",
    "        validation_steps=valid_steps,\n",
    "        epochs=epochs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T15:14:57.519965Z",
     "iopub.status.busy": "2022-06-12T15:14:57.518940Z",
     "iopub.status.idle": "2022-06-12T15:14:58.110084Z",
     "shell.execute_reply": "2022-06-12T15:14:58.109310Z",
     "shell.execute_reply.started": "2022-06-12T15:14:57.519927Z"
    }
   },
   "outputs": [],
   "source": [
    "acc = model_history.history['iou_score']\n",
    "val_acc = model_history.history['val_iou_score']\n",
    "\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training IOU score')\n",
    "plt.plot(val_acc, label='Validation IOU score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('IOU Score')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation IOU score with learning rate 1e-4')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss with learning rate 1e-4')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T13:34:12.894763Z",
     "iopub.status.busy": "2022-06-12T13:34:12.894144Z",
     "iopub.status.idle": "2022-06-12T13:34:12.898203Z",
     "shell.execute_reply": "2022-06-12T13:34:12.897464Z",
     "shell.execute_reply.started": "2022-06-12T13:34:12.894729Z"
    }
   },
   "source": [
    "# <center>Advanced ML pipeline with segmentation_models and Callbacks (W7S1) (Week 7 lecture reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:45:09.354442Z",
     "iopub.status.busy": "2022-06-12T16:45:09.353985Z",
     "iopub.status.idle": "2022-06-12T16:45:09.685487Z",
     "shell.execute_reply": "2022-06-12T16:45:09.684437Z",
     "shell.execute_reply.started": "2022-06-12T16:45:09.354409Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import math\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:45:12.378108Z",
     "iopub.status.busy": "2022-06-12T16:45:12.374496Z",
     "iopub.status.idle": "2022-06-12T16:45:12.502757Z",
     "shell.execute_reply": "2022-06-12T16:45:12.501554Z",
     "shell.execute_reply.started": "2022-06-12T16:45:12.378053Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Here load_data function is called. This will load the dataset paths and \n",
    "split it into X_train, X_test, y_train, y_test '''\n",
    "\n",
    "img_dir = '../input/artificial-lunar-rocky-landscape-dataset/images/render'\n",
    "mask_dir = '../input/artificial-lunar-rocky-landscape-dataset/images/clean'\n",
    "\n",
    "\n",
    "# let's get the list of image paths and mask paths in sorted order from the given directory respectively\n",
    "images = [os.path.join(img_dir, x) for x in sorted(os.listdir(img_dir))]\n",
    "masks = [os.path.join(mask_dir, x) for x in sorted(os.listdir(mask_dir))]\n",
    "\n",
    "\n",
    "# in this session, we will use our complete dataset\n",
    "X_train = images[:8000]\n",
    "y_train = masks[:8000]\n",
    "\n",
    "X_valid = images[8000:]\n",
    "y_valid = masks[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:45:15.755695Z",
     "iopub.status.busy": "2022-06-12T16:45:15.755237Z",
     "iopub.status.idle": "2022-06-12T16:45:15.773185Z",
     "shell.execute_reply": "2022-06-12T16:45:15.772019Z",
     "shell.execute_reply.started": "2022-06-12T16:45:15.755636Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here, `x_set` is list of path to the images\n",
    "# and `y_set` are the associated classes.\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\n",
    "class LunarDataset(Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size, dims, classes):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.img_height, self.img_width = dims\n",
    "        self.classes = classes\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        count = 0\n",
    "        # https://numpy.org/doc/stable/reference/generated/numpy.zeros.html\n",
    "        xtr = np.zeros((self.batch_size, self.img_height, self.img_width, 3))\n",
    "        for filename in batch_x:\n",
    "            img = imread(filename)[:self.img_height, :self.img_width, :] / 255.0\n",
    "            img = img.astype(np.float32)\n",
    "            xtr[count] = img\n",
    "            count += 1\n",
    "            \n",
    "        count = 0\n",
    "        ytr = np.zeros((self.batch_size, self.img_height, self.img_width, num_classes))\n",
    "        for filename in batch_y:\n",
    "            mask = imread(filename, as_gray = True)[:self.img_height, :self.img_width] // 0.07\n",
    "            mask[mask == 3] = 2\n",
    "            mask[mask == 10] = 3\n",
    "            \n",
    "            # one hot encoding our masks using to_categorical\n",
    "            # https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical\n",
    "            mask = to_categorical(mask, num_classes = 4)\n",
    "            ytr[count] = mask\n",
    "            count += 1\n",
    "\n",
    "        return xtr, ytr.astype(np.int32)\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "dims = (480, 480)\n",
    "num_classes = 4\n",
    "\n",
    "train_dataset = LunarDataset(X_train, y_train, batch_size, dims, num_classes)\n",
    "valid_dataset = LunarDataset(X_valid, y_valid, batch_size, dims, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:45:17.903374Z",
     "iopub.status.busy": "2022-06-12T16:45:17.902959Z",
     "iopub.status.idle": "2022-06-12T16:45:19.698942Z",
     "shell.execute_reply": "2022-06-12T16:45:19.697812Z",
     "shell.execute_reply.started": "2022-06-12T16:45:17.903342Z"
    }
   },
   "outputs": [],
   "source": [
    "sam = next(iter(train_dataset))\n",
    "\n",
    "sample = sam[1][1]\n",
    "\n",
    "i, v = np.unique(sample, return_counts = True)\n",
    "for a,b in zip(i,v):\n",
    "    print(a,\" \", b)\n",
    "    \n",
    "\n",
    "fig, (a1, a2, a3, a4) = plt.subplots(1, 4, figsize = (20, 5))\n",
    "\n",
    "a1.imshow(sample[:, :, 0])\n",
    "a2.imshow(sample[:, :, 1])\n",
    "a3.imshow(sample[:, :, 2])\n",
    "a4.imshow(sample[:, :, 3])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# four channels showing different classes\n",
    "# each channel have only 0 and 1 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:49:03.650983Z",
     "iopub.status.busy": "2022-06-12T16:49:03.650286Z",
     "iopub.status.idle": "2022-06-12T16:49:04.109894Z",
     "shell.execute_reply": "2022-06-12T16:49:04.108772Z",
     "shell.execute_reply.started": "2022-06-12T16:49:03.650937Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Step 1: Creating a base model \n",
    "\n",
    "IMG_SHAPE = (480, 480, 3)\n",
    "\n",
    "# include_top specify that we don't want to use the top layer (classifier)\n",
    "base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Step 2: Freezing the base\n",
    "\n",
    "# It is important to freeze the convolutional base before you compile and train the model.\n",
    "# Freezing prevents the weights in a given layer from being updated during training\n",
    "# VGG16 has many layers, so setting the entire model's trainable flag to False will freeze all of them.\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# Let's take a look at the base model architecture\n",
    "base_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "#### Step 3: Adding the head\n",
    "\n",
    "# inputs\n",
    "inputs = tf.keras.Input(shape=(480, 480, 3))\n",
    "\n",
    "# base with pretrained model\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# head layers\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(2)(x)\n",
    "\n",
    "# model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Let's take a look at the final model architecture\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# reference: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T15:15:00.294343Z",
     "iopub.status.busy": "2022-06-12T15:15:00.293979Z",
     "iopub.status.idle": "2022-06-12T15:15:10.577858Z",
     "shell.execute_reply": "2022-06-12T15:15:10.576474Z",
     "shell.execute_reply.started": "2022-06-12T15:15:00.294308Z"
    }
   },
   "outputs": [],
   "source": [
    "# run this command to directly install the library in our notebook\n",
    "\n",
    "!pip install segmentation_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T15:15:10.579934Z",
     "iopub.status.busy": "2022-06-12T15:15:10.579532Z",
     "iopub.status.idle": "2022-06-12T15:15:10.589047Z",
     "shell.execute_reply": "2022-06-12T15:15:10.586475Z",
     "shell.execute_reply.started": "2022-06-12T15:15:10.579890Z"
    }
   },
   "outputs": [],
   "source": [
    "# By default it tries to import keras, if it is not installed, it will try to start with tensorflow.keras framework\n",
    "\n",
    "import segmentation_models as sm\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "sm.set_framework('tf.keras')\n",
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T15:15:10.592196Z",
     "iopub.status.busy": "2022-06-12T15:15:10.591844Z",
     "iopub.status.idle": "2022-06-12T15:15:11.323136Z",
     "shell.execute_reply": "2022-06-12T15:15:11.322217Z",
     "shell.execute_reply.started": "2022-06-12T15:15:10.592168Z"
    }
   },
   "outputs": [],
   "source": [
    "BACKBONE = 'vgg16'\n",
    "input_shape = (480, 480, 3)\n",
    "n_classes = 4\n",
    "activation = 'softmax'\n",
    "\n",
    "# using segmentation_models to create U-net with vgg16 as a backbone\n",
    "# and pretrained imagenet weights\n",
    "\n",
    "# segmentation_model basically will create a mirror image of our backbone as expansion path and add to the contraction path\n",
    "model = sm.Unet(backbone_name = BACKBONE, \n",
    "                input_shape = input_shape, \n",
    "                classes = n_classes, \n",
    "                activation = activation,\n",
    "                encoder_weights = 'imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T15:15:11.325367Z",
     "iopub.status.busy": "2022-06-12T15:15:11.324381Z",
     "iopub.status.idle": "2022-06-12T15:15:11.886520Z",
     "shell.execute_reply": "2022-06-12T15:15:11.885080Z",
     "shell.execute_reply.started": "2022-06-12T15:15:11.325329Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters \"\"\"\n",
    "lr = 1e-4\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# metrics for result validation\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "# compiling the model\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = tf.keras.optimizers.Adam(lr), \n",
    "              metrics = metrics)\n",
    "\n",
    "train_steps = len(X_train)//batch_size\n",
    "valid_steps = len(X_valid)//batch_size\n",
    "\n",
    "\n",
    "\"\"\" Callbacks \"\"\"\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=f'models/lunarModel_{current_datetime}.h5',\n",
    "                        monitor='val_iou_score', verbose=0, \n",
    "                        mode='max', save_best_model=False),\n",
    "             \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_iou_score\", mode='max', patience=4,\n",
    "                          factor=0.1, verbose=0, min_lr=1e-6),\n",
    "             \n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_iou_score\", patience=5, verbose=0, mode='max'),\n",
    "\n",
    "        tf.keras.callbacks.TensorBoard(f'models/logs_{current_datetime}')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:43:27.013875Z",
     "iopub.status.busy": "2022-06-12T16:43:27.012920Z",
     "iopub.status.idle": "2022-06-12T16:43:27.031028Z",
     "shell.execute_reply": "2022-06-12T16:43:27.029542Z",
     "shell.execute_reply.started": "2022-06-12T16:43:27.013821Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "model_history = model.fit(train_dataset,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_data=valid_dataset,\n",
    "        validation_steps=valid_steps,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "# val_iou_score is expected to reach almost 0.8 after 5 epochs even without using callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:43:18.807352Z",
     "iopub.status.busy": "2022-06-12T16:43:18.806846Z",
     "iopub.status.idle": "2022-06-12T16:43:18.913436Z",
     "shell.execute_reply": "2022-06-12T16:43:18.911891Z",
     "shell.execute_reply.started": "2022-06-12T16:43:18.807265Z"
    }
   },
   "outputs": [],
   "source": [
    "acc = model_history.history['iou_score']\n",
    "val_acc = model_history.history['val_iou_score']\n",
    "\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training IOU score')\n",
    "plt.plot(val_acc, label='Validation IOU score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('IOU Score')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation IOU score with learning rate 1e-4')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss with learning rate 1e-4')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters \"\"\"\n",
    "lr = 1e-3\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "# metrics for result validation\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "# compiling the model\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = tf.keras.optimizers.Adam(lr), \n",
    "              metrics = metrics)\n",
    "\n",
    "train_steps = len(X_train)//batch_size\n",
    "valid_steps = len(X_valid)//batch_size\n",
    "\n",
    "\n",
    "\"\"\" Callbacks \"\"\"\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=f'models/lunarModel_{current_datetime}.h5',\n",
    "                        monitor='val_iou_score', verbose=0, \n",
    "                        mode='max', save_best_model=False),\n",
    "             \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_iou_score\", mode='max', patience=4,\n",
    "                          factor=0.1, verbose=0, min_lr=1e-6),\n",
    "             \n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_iou_score\", patience=5, verbose=0, mode='max'),\n",
    "\n",
    "        tf.keras.callbacks.TensorBoard(f'models/logs_{current_datetime}')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "model_history = model.fit(train_dataset,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_data=valid_dataset,\n",
    "        validation_steps=valid_steps,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "# val_iou_score is expected to reach almost 0.8 after 5 epochs even without using callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters \"\"\"\n",
    "lr = 1e-5\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "# metrics for result validation\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5,smooth=1e-5), sm.metrics.FScore(threshold=0.5,smooth=1e-5)]\n",
    "\n",
    "# compiling the model\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = tf.keras.optimizers.Adam(lr), \n",
    "              metrics = metrics)\n",
    "\n",
    "train_steps = len(X_train)//batch_size\n",
    "valid_steps = len(X_valid)//batch_size\n",
    "\n",
    "\n",
    "\"\"\" Callbacks \"\"\"\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=f'models/lunarModel_{current_datetime}.h5',\n",
    "                        monitor='val_iou_score', verbose=0, \n",
    "                        mode='max', save_best_model=False),\n",
    "             \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_iou_score\", mode='max', patience=4,\n",
    "                          factor=0.1, verbose=0, min_lr=1e-6),\n",
    "             \n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_iou_score\", patience=5, verbose=0, mode='max'),\n",
    "\n",
    "        tf.keras.callbacks.TensorBoard(f'models/logs_{current_datetime}')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "model_history = model.fit(train_dataset,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_data=valid_dataset,\n",
    "        validation_steps=valid_steps,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "# val_iou_score is expected to reach almost 0.8 after 5 epochs even without using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As tried on different learning rates and different parameters picked some optimized params and run on different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Resnet as backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:50:26.142478Z",
     "iopub.status.busy": "2022-06-12T16:50:26.141751Z",
     "iopub.status.idle": "2022-06-12T16:50:28.352596Z",
     "shell.execute_reply": "2022-06-12T16:50:28.350700Z",
     "shell.execute_reply.started": "2022-06-12T16:50:26.142446Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Step 1: Creating a base model \n",
    "\n",
    "IMG_SHAPE = (480, 480, 3)\n",
    "\n",
    "# include_top specify that we don't want to use the top layer (classifier)\n",
    "base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Step 2: Freezing the base\n",
    "\n",
    "# It is important to freeze the convolutional base before you compile and train the model.\n",
    "# Freezing prevents the weights in a given layer from being updated during training\n",
    "# VGG16 has many layers, so setting the entire model's trainable flag to False will freeze all of them.\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# Let's take a look at the base model architecture\n",
    "base_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "#### Step 3: Adding the head\n",
    "\n",
    "# inputs\n",
    "inputs = tf.keras.Input(shape=(480, 480, 3))\n",
    "\n",
    "# base with pretrained model\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# head layers\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(2)(x)\n",
    "\n",
    "# model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Let's take a look at the final model architecture\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# reference: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:50:33.830253Z",
     "iopub.status.busy": "2022-06-12T16:50:33.829752Z",
     "iopub.status.idle": "2022-06-12T16:50:35.349397Z",
     "shell.execute_reply": "2022-06-12T16:50:35.348340Z",
     "shell.execute_reply.started": "2022-06-12T16:50:33.830220Z"
    }
   },
   "outputs": [],
   "source": [
    "BACKBONE = 'resnet34'\n",
    "input_shape = (480, 480, 3)\n",
    "n_classes = 4\n",
    "activation = 'softmax'\n",
    "\n",
    "# using segmentation_models to create U-net with vgg16 as a backbone\n",
    "# and pretrained imagenet weights\n",
    "\n",
    "# segmentation_model basically will create a mirror image of our backbone as expansion path and add to the contraction path\n",
    "model = sm.Unet(backbone_name = BACKBONE, \n",
    "                input_shape = input_shape, \n",
    "                classes = n_classes, \n",
    "                activation = activation,\n",
    "                encoder_weights = 'imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:50:42.624584Z",
     "iopub.status.busy": "2022-06-12T16:50:42.623970Z",
     "iopub.status.idle": "2022-06-12T16:50:43.031998Z",
     "shell.execute_reply": "2022-06-12T16:50:43.029745Z",
     "shell.execute_reply.started": "2022-06-12T16:50:42.624527Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters \"\"\"\n",
    "lr = 1e-4\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# metrics for result validation\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "# compiling the model\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = tf.keras.optimizers.Adam(lr), \n",
    "              metrics = metrics)\n",
    "\n",
    "train_steps = len(X_train)//batch_size\n",
    "valid_steps = len(X_valid)//batch_size\n",
    "\n",
    "\n",
    "\"\"\" Callbacks \"\"\"\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=f'models/lunarModel_{current_datetime}.h5',\n",
    "                        monitor='val_iou_score', verbose=0, \n",
    "                        mode='max', save_best_model=False),\n",
    "             \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_iou_score\", mode='max', patience=4,\n",
    "                          factor=0.1, verbose=0, min_lr=1e-6),\n",
    "             \n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_iou_score\", patience=5, verbose=0, mode='max'),\n",
    "\n",
    "        tf.keras.callbacks.TensorBoard(f'models/logs_{current_datetime}')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:50:46.305611Z",
     "iopub.status.busy": "2022-06-12T16:50:46.304918Z",
     "iopub.status.idle": "2022-06-12T17:40:30.248443Z",
     "shell.execute_reply": "2022-06-12T17:40:30.247331Z",
     "shell.execute_reply.started": "2022-06-12T16:50:46.305577Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "model_history = model.fit(train_dataset,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_data=valid_dataset,\n",
    "        validation_steps=valid_steps,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "# val_iou_score is expected to reach almost 0.8 after 5 epochs even without using callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T17:42:20.435564Z",
     "iopub.status.busy": "2022-06-12T17:42:20.434730Z",
     "iopub.status.idle": "2022-06-12T17:42:20.442369Z",
     "shell.execute_reply": "2022-06-12T17:42:20.440416Z",
     "shell.execute_reply.started": "2022-06-12T17:42:20.435529Z"
    }
   },
   "outputs": [],
   "source": [
    "model_history1=model_history.history\n",
    "print(model_history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T17:42:22.467686Z",
     "iopub.status.busy": "2022-06-12T17:42:22.466910Z",
     "iopub.status.idle": "2022-06-12T17:42:22.835928Z",
     "shell.execute_reply": "2022-06-12T17:42:22.834757Z",
     "shell.execute_reply.started": "2022-06-12T17:42:22.467643Z"
    }
   },
   "outputs": [],
   "source": [
    "acc = model_history.history['iou_score']\n",
    "val_acc = model_history.history['val_iou_score']\n",
    "\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training IOU score')\n",
    "plt.plot(val_acc, label='Validation IOU score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('IOU Score')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation IOU score with learning rate 1e-4')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss with learning rate 1e-4')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'resnet50'\n",
    "input_shape = (480, 480, 3)\n",
    "n_classes = 4\n",
    "activation = 'softmax'\n",
    "\n",
    "# using segmentation_models to create U-net with vgg16 as a backbone\n",
    "# and pretrained imagenet weights\n",
    "\n",
    "# segmentation_model basically will create a mirror image of our backbone as expansion path and add to the contraction path\n",
    "model = sm.Unet(backbone_name = BACKBONE, \n",
    "                input_shape = input_shape, \n",
    "                classes = n_classes, \n",
    "                activation = activation,\n",
    "                encoder_weights = 'imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters \"\"\"\n",
    "lr = 1e-4\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# metrics for result validation\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "# compiling the model\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = tf.keras.optimizers.Adam(lr), \n",
    "              metrics = metrics)\n",
    "\n",
    "train_steps = len(X_train)//batch_size\n",
    "valid_steps = len(X_valid)//batch_size\n",
    "\n",
    "\n",
    "\"\"\" Callbacks \"\"\"\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=f'models/lunarModel_{current_datetime}.h5',\n",
    "                        monitor='val_iou_score', verbose=0, \n",
    "                        mode='max', save_best_model=False),\n",
    "             \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_iou_score\", mode='max', patience=4,\n",
    "                          factor=0.1, verbose=0, min_lr=1e-6),\n",
    "             \n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_iou_score\", patience=5, verbose=0, mode='max'),\n",
    "\n",
    "        tf.keras.callbacks.TensorBoard(f'models/logs_{current_datetime}')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "model_history = model.fit(train_dataset,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_data=valid_dataset,\n",
    "        validation_steps=valid_steps,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "# val_iou_score is expected to reach almost 0.8 after 5 epochs even without using callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history2=model_history.history\n",
    "print(model_history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model_history.history['iou_score']\n",
    "val_acc = model_history.history['val_iou_score']\n",
    "\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training IOU score')\n",
    "plt.plot(val_acc, label='Validation IOU score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('IOU Score')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation IOU score with learning rate 1e-4')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss with learning rate 1e-4')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Inception as backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'inceptionv3'\n",
    "input_shape = (480, 480, 3)\n",
    "n_classes = 4\n",
    "activation = 'softmax'\n",
    "\n",
    "# using segmentation_models to create U-net with vgg16 as a backbone\n",
    "# and pretrained imagenet weights\n",
    "\n",
    "# segmentation_model basically will create a mirror image of our backbone as expansion path and add to the contraction path\n",
    "model = sm.Unet(backbone_name = BACKBONE, \n",
    "                input_shape = input_shape, \n",
    "                classes = n_classes, \n",
    "                activation = activation,\n",
    "                encoder_weights = 'imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters \"\"\"\n",
    "lr = 1e-4\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# metrics for result validation\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "# compiling the model\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = tf.keras.optimizers.Adam(lr), \n",
    "              metrics = metrics)\n",
    "\n",
    "train_steps = len(X_train)//batch_size\n",
    "valid_steps = len(X_valid)//batch_size\n",
    "\n",
    "\n",
    "\"\"\" Callbacks \"\"\"\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=f'models/lunarModel_{current_datetime}.h5',\n",
    "                        monitor='val_iou_score', verbose=0, \n",
    "                        mode='max', save_best_model=False),\n",
    "             \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_iou_score\", mode='max', patience=4,\n",
    "                          factor=0.1, verbose=0, min_lr=1e-6),\n",
    "             \n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_iou_score\", patience=5, verbose=0, mode='max'),\n",
    "\n",
    "        tf.keras.callbacks.TensorBoard(f'models/logs_{current_datetime}')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "model_history = model.fit(train_dataset,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_data=valid_dataset,\n",
    "        validation_steps=valid_steps,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "# val_iou_score is expected to reach almost 0.8 after 5 epochs even without using callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history3=model_history.history\n",
    "print(model_history3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model_history.history['iou_score']\n",
    "val_acc = model_history.history['val_iou_score']\n",
    "\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training IOU score')\n",
    "plt.plot(val_acc, label='Validation IOU score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('IOU Score')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation IOU score with learning rate 1e-4')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss with learning rate 1e-4')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'inceptionresnetv2'\n",
    "input_shape = (480, 480, 3)\n",
    "n_classes = 4\n",
    "activation = 'softmax'\n",
    "\n",
    "# using segmentation_models to create U-net with vgg16 as a backbone\n",
    "# and pretrained imagenet weights\n",
    "\n",
    "# segmentation_model basically will create a mirror image of our backbone as expansion path and add to the contraction path\n",
    "model = sm.Unet(backbone_name = BACKBONE, \n",
    "                input_shape = input_shape, \n",
    "                classes = n_classes, \n",
    "                activation = activation,\n",
    "                encoder_weights = 'imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters \"\"\"\n",
    "lr = 1e-4\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# metrics for result validation\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "# compiling the model\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = tf.keras.optimizers.Adam(lr), \n",
    "              metrics = metrics)\n",
    "\n",
    "train_steps = len(X_train)//batch_size\n",
    "valid_steps = len(X_valid)//batch_size\n",
    "\n",
    "\n",
    "\"\"\" Callbacks \"\"\"\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=f'models/lunarModel_{current_datetime}.h5',\n",
    "                        monitor='val_iou_score', verbose=0, \n",
    "                        mode='max', save_best_model=False),\n",
    "             \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_iou_score\", mode='max', patience=4,\n",
    "                          factor=0.1, verbose=0, min_lr=1e-6),\n",
    "             \n",
    "#         tf.keras.callbacks.EarlyStopping(monitor=\"val_iou_score\", patience=5, verbose=0, mode='max'),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_iou_score\", patience=1, verbose=0, mode='max',min_delta=0.01),\n",
    "\n",
    "        tf.keras.callbacks.TensorBoard(f'models/logs_{current_datetime}')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "model_history = model.fit(train_dataset,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_data=valid_dataset,\n",
    "        validation_steps=valid_steps,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "# val_iou_score is expected to reach almost 0.8 after 5 epochs even without using callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history4=model_history.history\n",
    "print(model_history4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model_history.history['iou_score']\n",
    "val_acc = model_history.history['val_iou_score']\n",
    "\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training IOU score')\n",
    "plt.plot(val_acc, label='Validation IOU score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('IOU Score')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation IOU score with learning rate 1e-4')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss with learning rate 1e-4')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1OFxBbnxC_I"
   },
   "source": [
    "## [IMPORTANT] Paste you final model training history here in the markdown.(just double click this line, and you'll be able to edit it. \n",
    "\n",
    "NOTE: If we find that your actual model score and what you paste here is differing, your assignment will get rejected.  \n",
    "\n",
    "here ----\n",
    "\n",
    "# After all these models achieved val_iou_score is in between .80 to .82\n",
    "The stable incemental epochs observed in InceptionResnetv2\n",
    "\n",
    "Epoch 1/10\n",
    "  1/250 [..............................] - ETA: 1:28:37 - loss: 2.1726 - iou_score: 0.0203 - f1-score: 0.0393\n",
    "2022-06-12 15:07:01.130978: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
    "2022-06-12 15:07:01.131042: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
    "  2/250 [..............................] - ETA: 7:44 - loss: 2.1149 - iou_score: 0.0192 - f1-score: 0.0371  \n",
    "2022-06-12 15:07:03.723045: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
    "2022-06-12 15:07:03.732656: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
    "2022-06-12 15:07:03.923661: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 5964 callback api events and 5960 activity events.\n",
    "2022-06-12 15:07:04.080956: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
    "2022-06-12 15:07:04.259236: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04\n",
    "\n",
    "2022-06-12 15:07:04.358257: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04/14dbc38ab93a.trace.json.gz\n",
    "2022-06-12 15:07:04.568185: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04\n",
    "\n",
    "2022-06-12 15:07:04.577136: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04/14dbc38ab93a.memory_profile.json.gz\n",
    "2022-06-12 15:07:04.586890: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04\n",
    "Dumped tool data for xplane.pb to models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04/14dbc38ab93a.xplane.pb\n",
    "Dumped tool data for overview_page.pb to models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04/14dbc38ab93a.overview_page.pb\n",
    "Dumped tool data for input_pipeline.pb to models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04/14dbc38ab93a.input_pipeline.pb\n",
    "Dumped tool data for tensorflow_stats.pb to models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04/14dbc38ab93a.tensorflow_stats.pb\n",
    "Dumped tool data for kernel_stats.pb to models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04/14dbc38ab93a.kernel_stats.pb\n",
    "\n",
    "250/250 [==============================] - 393s 1s/step - loss: 0.6413 - iou_score: 0.4547 - f1-score: 0.5372 - val_loss: 0.3477 - val_iou_score: 0.6490 - val_f1-score: 0.7417\n",
    "Epoch 2/10\n",
    "250/250 [==============================] - 370s 1s/step - loss: 0.2104 - iou_score: 0.7187 - f1-score: 0.8082 - val_loss: 0.1596 - val_iou_score: 0.7190 - val_f1-score: 0.8063\n",
    "Epoch 3/10\n",
    "250/250 [==============================] - 367s 1s/step - loss: 0.1368 - iou_score: 0.7788 - f1-score: 0.8590 - val_loss: 0.1148 - val_iou_score: 0.7886 - val_f1-score: 0.8659\n",
    "Epoch 4/10\n",
    "250/250 [==============================] - 327s 1s/step - loss: 0.1142 - iou_score: 0.7974 - f1-score: 0.8736 - val_loss: 0.1020 - val_iou_score: 0.8077 - val_f1-score: 0.8808\n",
    "Epoch 5/10\n",
    "250/250 [==============================] - 327s 1s/step - loss: 0.1024 - iou_score: 0.8052 - f1-score: 0.8790 - val_loss: 0.0998 - val_iou_score: 0.8025 - val_f1-score: 0.8767\n",
    "Epoch 6/10\n",
    "250/250 [==============================] - 328s 1s/step - loss: 0.0985 - iou_score: 0.8144 - f1-score: 0.8861 - val_loss: 0.0993 - val_iou_score: 0.7735 - val_f1-score: 0.8536\n",
    "Epoch 7/10\n",
    "250/250 [==============================] - 329s 1s/step - loss: 0.0875 - iou_score: 0.8268 - f1-score: 0.8947 - val_loss: 0.0893 - val_iou_score: 0.8186 - val_f1-score: 0.8882\n",
    "Epoch 8/10\n",
    "250/250 [==============================] - 367s 1s/step - loss: 0.0820 - iou_score: 0.8319 - f1-score: 0.8987 - val_loss: 0.0904 - val_iou_score: 0.8121 - val_f1-score: 0.8832\n",
    "Epoch 9/10\n",
    "250/250 [==============================] - 368s 1s/step - loss: 0.0748 - iou_score: 0.8427 - f1-score: 0.9067 - val_loss: 0.0844 - val_iou_score: 0.8228 - val_f1-score: 0.8918\n",
    "Epoch 10/10\n",
    "250/250 [==============================] - 328s 1s/step - loss: 0.0735 - iou_score: 0.8430 - f1-score: 0.9064 - val_loss: 0.0938 - val_iou_score: 0.7771 - val_f1-score: 0.8568\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8f68O0lxXuP"
   },
   "source": [
    "I have tried out some experiments on parameters to tweak some optimal parameters and checking the results with very less epochs and found that changing the optimal parameters did not result in quite a change in results towards desired results.  \n",
    "\n",
    "Based on the experimented results I went on testing multiple standard models (ResNet and Inception) as backbone and performed transfer learning and collected inferences.\n",
    "\n",
    "ResNet is a stable model which is good for Feaure extraction.\n",
    "Inception is a very deep network and also it uttilises computing resources efficiently and is well known for it's accuracy.\n",
    "\n",
    "The results from the mix of models can be witnessed in the above tests(code blocks).\n",
    "\n",
    "Observed observations:\n",
    "For 10 epochs, almost all models gives val_iou_score nearly 0.8.\n",
    "InceptionResNetv2 scored better accuracy in the begning compared to other models.\n",
    "InceptionResNetv2was run for another 10 epochs with \"min_delta\" parameter in \"Early Stopping\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 epochs ofResNet\n",
    "\n",
    "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
    "  category=CustomMaskWarning)\n",
    "2022-06-12 16:50:47.510453: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
    "Epoch 1/10\n",
    "2022-06-12 16:50:55.469730: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n",
    "  1/250 [..............................] - ETA: 1:11:14 - loss: 2.5629 - iou_score: 0.0090 - f1-score: 0.0177\n",
    "2022-06-12 16:51:05.170845: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
    "2022-06-12 16:51:05.173545: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
    "  2/250 [..............................] - ETA: 6:08 - loss: 2.4813 - iou_score: 0.0114 - f1-score: 0.0223   \n",
    "2022-06-12 16:51:06.217819: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
    "2022-06-12 16:51:06.219584: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
    "2022-06-12 16:51:06.374846: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 1360 callback api events and 1356 activity events. \n",
    "2022-06-12 16:51:06.432439: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
    "2022-06-12 16:51:06.495599: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: models/logs_20220612-165042/train/plugins/profile/2022_06_12_16_51_06\n",
    "\n",
    "2022-06-12 16:51:06.526933: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to models/logs_20220612-165042/train/plugins/profile/2022_06_12_16_51_06/a9df19ac2169.trace.json.gz\n",
    "2022-06-12 16:51:06.632621: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: models/logs_20220612-165042/train/plugins/profile/2022_06_12_16_51_06\n",
    "\n",
    "2022-06-12 16:51:06.642475: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to models/logs_20220612-165042/train/plugins/profile/2022_06_12_16_51_06/a9df19ac2169.memory_profile.json.gz\n",
    "2022-06-12 16:51:06.647043: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: models/logs_20220612-165042/train/plugins/profile/2022_06_12_16_51_06\n",
    "Dumped tool data for xplane.pb to models/logs_20220612-165042/train/plugins/profile/2022_06_12_16_51_06/a9df19ac2169.xplane.pb\n",
    "Dumped tool data for overview_page.pb to models/logs_20220612-165042/train/plugins/profile/2022_06_12_16_51_06/a9df19ac2169.overview_page.pb\n",
    "Dumped tool data for input_pipeline.pb to models/logs_20220612-165042/train/plugins/profile/2022_06_12_16_51_06/a9df19ac2169.input_pipeline.pb\n",
    "Dumped tool data for tensorflow_stats.pb to models/logs_20220612-165042/train/plugins/profile/2022_06_12_16_51_06/a9df19ac2169.tensorflow_stats.pb\n",
    "Dumped tool data for kernel_stats.pb to models/logs_20220612-165042/train/plugins/profile/2022_06_12_16_51_06/a9df19ac2169.kernel_stats.pb\n",
    "\n",
    "250/250 [==============================] - 376s 1s/step - loss: 0.8468 - iou_score: 0.3734 - f1-score: 0.4427 - val_loss: 1.3447 - val_iou_score: 0.0019 - val_f1-score: 0.0038\n",
    "Epoch 2/10\n",
    "250/250 [==============================] - 331s 1s/step - loss: 0.3897 - iou_score: 0.6389 - f1-score: 0.7390 - val_loss: 0.6531 - val_iou_score: 0.2620 - val_f1-score: 0.3393\n",
    "Epoch 3/10\n",
    "250/250 [==============================] - 308s 1s/step - loss: 0.2275 - iou_score: 0.7300 - f1-score: 0.8190 - val_loss: 0.2898 - val_iou_score: 0.4909 - val_f1-score: 0.5403\n",
    "Epoch 4/10\n",
    "250/250 [==============================] - 269s 1s/step - loss: 0.1560 - iou_score: 0.7684 - f1-score: 0.8505 - val_loss: 0.1811 - val_iou_score: 0.6150 - val_f1-score: 0.6971\n",
    "Epoch 5/10\n",
    "250/250 [==============================] - 261s 1s/step - loss: 0.1242 - iou_score: 0.7843 - f1-score: 0.8635 - val_loss: 0.1156 - val_iou_score: 0.7714 - val_f1-score: 0.8525\n",
    "Epoch 6/10\n",
    "250/250 [==============================] - 246s 981ms/step - loss: 0.1090 - iou_score: 0.7948 - f1-score: 0.8714 - val_loss: 0.1164 - val_iou_score: 0.7715 - val_f1-score: 0.8518\n",
    "Epoch 7/10\n",
    "250/250 [==============================] - 256s 1s/step - loss: 0.0994 - iou_score: 0.8038 - f1-score: 0.8783 - val_loss: 0.0997 - val_iou_score: 0.7979 - val_f1-score: 0.8732\n",
    "Epoch 8/10\n",
    "250/250 [==============================] - 260s 1s/step - loss: 0.0902 - iou_score: 0.8137 - f1-score: 0.8859 - val_loss: 0.1022 - val_iou_score: 0.7556 - val_f1-score: 0.8386\n",
    "Epoch 9/10\n",
    "250/250 [==============================] - 297s 1s/step - loss: 0.0842 - iou_score: 0.8188 - f1-score: 0.8893 - val_loss: 0.0917 - val_iou_score: 0.8090 - val_f1-score: 0.8810\n",
    "Epoch 10/10\n",
    "250/250 [==============================] - 297s 1s/step - loss: 0.0779 - iou_score: 0.8267 - f1-score: 0.8953 - val_loss: 0.1012 - val_iou_score: 0.7576 - val_f1-score: 0.8385"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First 10 epochs of InceptionResNetv2\n",
    "\n",
    "Epoch 1/10\n",
    "  1/250 [..............................] - ETA: 1:28:37 - loss: 2.1726 - iou_score: 0.0203 - f1-score: 0.0393\n",
    "2022-06-12 15:07:01.130978: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
    "2022-06-12 15:07:01.131042: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
    "  2/250 [..............................] - ETA: 7:44 - loss: 2.1149 - iou_score: 0.0192 - f1-score: 0.0371  \n",
    "2022-06-12 15:07:03.723045: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
    "2022-06-12 15:07:03.732656: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
    "2022-06-12 15:07:03.923661: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 5964 callback api events and 5960 activity events.\n",
    "2022-06-12 15:07:04.080956: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
    "2022-06-12 15:07:04.259236: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04\n",
    "\n",
    "2022-06-12 15:07:04.358257: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04/14dbc38ab93a.trace.json.gz\n",
    "2022-06-12 15:07:04.568185: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04\n",
    "\n",
    "2022-06-12 15:07:04.577136: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04/14dbc38ab93a.memory_profile.json.gz\n",
    "2022-06-12 15:07:04.586890: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04\n",
    "Dumped tool data for xplane.pb to models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04/14dbc38ab93a.xplane.pb\n",
    "Dumped tool data for overview_page.pb to models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04/14dbc38ab93a.overview_page.pb\n",
    "Dumped tool data for input_pipeline.pb to models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04/14dbc38ab93a.input_pipeline.pb\n",
    "Dumped tool data for tensorflow_stats.pb to models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04/14dbc38ab93a.tensorflow_stats.pb\n",
    "Dumped tool data for kernel_stats.pb to models/logs_20220612-150635/train/plugins/profile/2022_06_12_15_07_04/14dbc38ab93a.kernel_stats.pb\n",
    "\n",
    "250/250 [==============================] - 393s 1s/step - loss: 0.6413 - iou_score: 0.4547 - f1-score: 0.5372 - val_loss: 0.3477 - val_iou_score: 0.6490 - val_f1-score: 0.7417\n",
    "Epoch 2/10\n",
    "250/250 [==============================] - 370s 1s/step - loss: 0.2104 - iou_score: 0.7187 - f1-score: 0.8082 - val_loss: 0.1596 - val_iou_score: 0.7190 - val_f1-score: 0.8063\n",
    "Epoch 3/10\n",
    "250/250 [==============================] - 367s 1s/step - loss: 0.1368 - iou_score: 0.7788 - f1-score: 0.8590 - val_loss: 0.1148 - val_iou_score: 0.7886 - val_f1-score: 0.8659\n",
    "Epoch 4/10\n",
    "250/250 [==============================] - 327s 1s/step - loss: 0.1142 - iou_score: 0.7974 - f1-score: 0.8736 - val_loss: 0.1020 - val_iou_score: 0.8077 - val_f1-score: 0.8808\n",
    "Epoch 5/10\n",
    "250/250 [==============================] - 327s 1s/step - loss: 0.1024 - iou_score: 0.8052 - f1-score: 0.8790 - val_loss: 0.0998 - val_iou_score: 0.8025 - val_f1-score: 0.8767\n",
    "Epoch 6/10\n",
    "250/250 [==============================] - 328s 1s/step - loss: 0.0985 - iou_score: 0.8144 - f1-score: 0.8861 - val_loss: 0.0993 - val_iou_score: 0.7735 - val_f1-score: 0.8536\n",
    "Epoch 7/10\n",
    "250/250 [==============================] - 329s 1s/step - loss: 0.0875 - iou_score: 0.8268 - f1-score: 0.8947 - val_loss: 0.0893 - val_iou_score: 0.8186 - val_f1-score: 0.8882\n",
    "Epoch 8/10\n",
    "250/250 [==============================] - 367s 1s/step - loss: 0.0820 - iou_score: 0.8319 - f1-score: 0.8987 - val_loss: 0.0904 - val_iou_score: 0.8121 - val_f1-score: 0.8832\n",
    "Epoch 9/10\n",
    "250/250 [==============================] - 368s 1s/step - loss: 0.0748 - iou_score: 0.8427 - f1-score: 0.9067 - val_loss: 0.0844 - val_iou_score: 0.8228 - val_f1-score: 0.8918\n",
    "Epoch 10/10\n",
    "250/250 [==============================] - 328s 1s/step - loss: 0.0735 - iou_score: 0.8430 - f1-score: 0.9064 - val_loss: 0.0938 - val_iou_score: 0.7771 - val_f1-score: 0.8568"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next 10 epochs with early stopping (8 epochs reached)\n",
    "\n",
    "Epoch 1/10\n",
    "  1/250 [..............................] - ETA: 1:18:04 - loss: 0.0353 - iou_score: 0.8824 - f1-score: 0.9339\n",
    "2022-06-12 17:21:26.540918: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
    "2022-06-12 17:21:26.540973: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
    "  2/250 [..............................] - ETA: 6:58 - loss: 0.0438 - iou_score: 0.8481 - f1-score: 0.9115   \n",
    "2022-06-12 17:21:29.221979: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
    "2022-06-12 17:21:29.233435: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
    "2022-06-12 17:21:29.419171: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 5964 callback api events and 5960 activity events. \n",
    "2022-06-12 17:21:29.572608: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
    "2022-06-12 17:21:29.742585: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: models/logs_20220612-172102/train/plugins/profile/2022_06_12_17_21_29\n",
    "\n",
    "2022-06-12 17:21:29.844091: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to models/logs_20220612-172102/train/plugins/profile/2022_06_12_17_21_29/14dbc38ab93a.trace.json.gz\n",
    "2022-06-12 17:21:30.049926: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: models/logs_20220612-172102/train/plugins/profile/2022_06_12_17_21_29\n",
    "\n",
    "2022-06-12 17:21:30.058949: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to models/logs_20220612-172102/train/plugins/profile/2022_06_12_17_21_29/14dbc38ab93a.memory_profile.json.gz\n",
    "2022-06-12 17:21:30.067939: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: models/logs_20220612-172102/train/plugins/profile/2022_06_12_17_21_29\n",
    "Dumped tool data for xplane.pb to models/logs_20220612-172102/train/plugins/profile/2022_06_12_17_21_29/14dbc38ab93a.xplane.pb\n",
    "Dumped tool data for overview_page.pb to models/logs_20220612-172102/train/plugins/profile/2022_06_12_17_21_29/14dbc38ab93a.overview_page.pb\n",
    "Dumped tool data for input_pipeline.pb to models/logs_20220612-172102/train/plugins/profile/2022_06_12_17_21_29/14dbc38ab93a.input_pipeline.pb\n",
    "Dumped tool data for tensorflow_stats.pb to models/logs_20220612-172102/train/plugins/profile/2022_06_12_17_21_29/14dbc38ab93a.tensorflow_stats.pb\n",
    "Dumped tool data for kernel_stats.pb to models/logs_20220612-172102/train/plugins/profile/2022_06_12_17_21_29/14dbc38ab93a.kernel_stats.pb\n",
    "\n",
    "250/250 [==============================] - 391s 1s/step - loss: 0.0697 - iou_score: 0.8466 - f1-score: 0.9088 - val_loss: 0.0931 - val_iou_score: 0.8057 - val_f1-score: 0.8794\n",
    "Epoch 2/10\n",
    "250/250 [==============================] - 369s 1s/step - loss: 0.0750 - iou_score: 0.8393 - f1-score: 0.9044 - val_loss: 0.0869 - val_iou_score: 0.8110 - val_f1-score: 0.8829\n",
    "Epoch 3/10\n",
    "250/250 [==============================] - 367s 1s/step - loss: 0.0625 - iou_score: 0.8544 - f1-score: 0.9146 - val_loss: 0.0872 - val_iou_score: 0.8249 - val_f1-score: 0.8932\n",
    "Epoch 4/10\n",
    "250/250 [==============================] - 329s 1s/step - loss: 0.0605 - iou_score: 0.8556 - f1-score: 0.9155 - val_loss: 0.1005 - val_iou_score: 0.8225 - val_f1-score: 0.8913\n",
    "Epoch 5/10\n",
    "250/250 [==============================] - 368s 1s/step - loss: 0.0615 - iou_score: 0.8529 - f1-score: 0.9135 - val_loss: 0.0933 - val_iou_score: 0.8029 - val_f1-score: 0.8765\n",
    "Epoch 6/10\n",
    "250/250 [==============================] - 327s 1s/step - loss: 0.0570 - iou_score: 0.8580 - f1-score: 0.9167 - val_loss: 0.0933 - val_iou_score: 0.8096 - val_f1-score: 0.8815\n",
    "Epoch 7/10\n",
    "250/250 [==============================] - 368s 1s/step - loss: 0.0488 - iou_score: 0.8690 - f1-score: 0.9241 - val_loss: 0.1256 - val_iou_score: 0.7895 - val_f1-score: 0.8666\n",
    "Epoch 8/10\n",
    "250/250 [==============================] - 368s 1s/step - loss: 0.0471 - iou_score: 0.8678 - f1-score: 0.9227 - val_loss: 0.0908 - val_iou_score: 0.8294 - val_f1-score: 0.8962"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
