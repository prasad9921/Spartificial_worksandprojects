{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVl26Wc2igtT"
   },
   "source": [
    "# Implementing Convolutional Neural Network for Image Classification\n",
    "## Let's first load and preprocess our images\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:07:10.346276Z",
     "iopub.status.busy": "2022-05-12T07:07:10.345972Z",
     "iopub.status.idle": "2022-05-12T07:07:16.110253Z",
     "shell.execute_reply": "2022-05-12T07:07:16.109488Z",
     "shell.execute_reply.started": "2022-05-12T07:07:10.346199Z"
    },
    "id": "Mdqq5rNKigtV"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os \n",
    "import PIL \n",
    "from PIL import Image \n",
    "import tensorflow as tf \n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDvBEAWWigtW"
   },
   "source": [
    "# Import the flowers dataset\n",
    "## From Add data button on the top right corner, import \"flower-photos-by-the-tensorflow-team\" dataset.\n",
    "## This tutorial uses a dataset of several thousand photos of flowers. \n",
    "## The flowers dataset contains five sub-directories, one per class:\n",
    "\n",
    "flowers_photos/\n",
    "\n",
    "daisy/\n",
    "\n",
    "dandelion/\n",
    "\n",
    "roses/\n",
    "\n",
    "sunflowers/\n",
    "\n",
    "tulips/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:07:21.736352Z",
     "iopub.status.busy": "2022-05-12T07:07:21.735648Z",
     "iopub.status.idle": "2022-05-12T07:07:21.74002Z",
     "shell.execute_reply": "2022-05-12T07:07:21.739183Z",
     "shell.execute_reply.started": "2022-05-12T07:07:21.73632Z"
    },
    "id": "4VOm53AdigtX"
   },
   "outputs": [],
   "source": [
    "# path for the root dataset directory\n",
    "data_dir = \"../input/flower-photos-by-the-tensorflow-team/flower_photos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQF5liwuigtX"
   },
   "source": [
    "## After downloading (218MB), you should now have a copy of the flower photos available. There are 3,670 total images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:08:32.86159Z",
     "iopub.status.busy": "2022-05-12T07:08:32.861331Z",
     "iopub.status.idle": "2022-05-12T07:08:32.876381Z",
     "shell.execute_reply": "2022-05-12T07:08:32.875651Z",
     "shell.execute_reply.started": "2022-05-12T07:08:32.861562Z"
    },
    "id": "7rta0zWjigtY"
   },
   "outputs": [],
   "source": [
    "# let's see how many classes we have in our dataset\n",
    "classes = os.listdir(data_dir)\n",
    "classes.remove(\"LICENSE.txt\")\n",
    "\n",
    "# counting number of images per class\n",
    "image_count = [len(os.listdir(os.path.join(data_dir,classes[i]))) for i in range(5)]\n",
    "\n",
    "print(classes)\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g94MDOm2igtY"
   },
   "source": [
    "## Before moving forward and building our super-cool TF model, let's look at the dataset a lil bit..\n",
    "\n",
    "## Let's Google our dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fhp5iuaYigtZ"
   },
   "source": [
    "# Each directory contains images of that type of flower. Here are some roses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:15:13.211731Z",
     "iopub.status.busy": "2022-05-12T07:15:13.211445Z",
     "iopub.status.idle": "2022-05-12T07:15:13.244128Z",
     "shell.execute_reply": "2022-05-12T07:15:13.243479Z",
     "shell.execute_reply.started": "2022-05-12T07:15:13.211679Z"
    },
    "id": "Xq-yuTSwigtZ"
   },
   "outputs": [],
   "source": [
    "roses = os.listdir(os.path.join(data_dir, \"roses\"))\n",
    "\n",
    "img = Image.open(os.path.join(data_dir, \"roses\", roses[8]))\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GU2uXbhcigta"
   },
   "source": [
    "# Load data using a Keras utility\n",
    "## Let's load these images off our Kaggle kernel using the helpful **tf.keras.utils.image_dataset_from_directory** utility.\n",
    "## Create a dataset, essentially!\n",
    "## Start with defining some parameters for the loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:19:01.802412Z",
     "iopub.status.busy": "2022-05-12T07:19:01.80215Z",
     "iopub.status.idle": "2022-05-12T07:19:01.806498Z",
     "shell.execute_reply": "2022-05-12T07:19:01.805502Z",
     "shell.execute_reply.started": "2022-05-12T07:19:01.802382Z"
    },
    "id": "Q1-irb8Yigta"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jDxdC2Kigta"
   },
   "source": [
    "## It's good practice to use a validation split when developing your model. You will use 80% of the images for training and 20% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:20:34.256419Z",
     "iopub.status.busy": "2022-05-12T07:20:34.255888Z",
     "iopub.status.idle": "2022-05-12T07:20:34.64473Z",
     "shell.execute_reply": "2022-05-12T07:20:34.644015Z",
     "shell.execute_reply.started": "2022-05-12T07:20:34.256382Z"
    },
    "id": "jfY6v7YOigtb"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:19:56.680624Z",
     "iopub.status.busy": "2022-05-12T07:19:56.679907Z",
     "iopub.status.idle": "2022-05-12T07:19:57.049072Z",
     "shell.execute_reply": "2022-05-12T07:19:57.048354Z",
     "shell.execute_reply.started": "2022-05-12T07:19:56.680584Z"
    },
    "id": "w7lkj-Ycigtb"
   },
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WU4Chprtigtb"
   },
   "source": [
    "## We used a random seed. What's that all about?!\n",
    "Check here: https://towardsdatascience.com/how-to-use-random-seeds-effectively-54a4cd855a79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gL8JCp2Rigtb"
   },
   "source": [
    "## You can find the class names in the class_names attribute on these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:29:42.122791Z",
     "iopub.status.busy": "2022-05-12T07:29:42.122249Z",
     "iopub.status.idle": "2022-05-12T07:29:42.127052Z",
     "shell.execute_reply": "2022-05-12T07:29:42.126128Z",
     "shell.execute_reply.started": "2022-05-12T07:29:42.122752Z"
    },
    "id": "Vsowj_n2igtc"
   },
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WMwrm_Vigtc"
   },
   "source": [
    "# Visualize the data\n",
    "## Here are the first nine images from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:30:38.589385Z",
     "iopub.status.busy": "2022-05-12T07:30:38.589115Z",
     "iopub.status.idle": "2022-05-12T07:30:39.771175Z",
     "shell.execute_reply": "2022-05-12T07:30:39.770525Z",
     "shell.execute_reply.started": "2022-05-12T07:30:38.589355Z"
    },
    "id": "7bTmOPkMigtc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1): # Only take a single example\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gjgkbXwigtc"
   },
   "source": [
    "### You can train a model using these datasets by passing them to model.fit (shown later in this tutorial). \n",
    "### If you like, you can also manually iterate over the dataset and retrieve batches of images:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ondtVb0mkymO"
   },
   "source": [
    "### How to get batches of images and labels? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:31:16.114661Z",
     "iopub.status.busy": "2022-05-12T07:31:16.114196Z",
     "iopub.status.idle": "2022-05-12T07:31:16.753116Z",
     "shell.execute_reply": "2022-05-12T07:31:16.752357Z",
     "shell.execute_reply.started": "2022-05-12T07:31:16.114626Z"
    },
    "id": "QNhGVZgdigtc"
   },
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQr4T3y6lTc2"
   },
   "source": [
    "### Why this works: https://keras.io/api/preprocessing/image/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-L6_IeLAigtd"
   },
   "source": [
    "### The image_batch is a tensor of the shape (32, 180, 180, 3). \n",
    "### This is a batch of 32 images of shape 180x180x3 (the last dimension refers to color channels RGB). \n",
    "### The label_batch is a tensor of the shape (32,), these are corresponding labels to the 32 images.\n",
    "### You can call .numpy() on either of these tensors to convert them to a numpy.ndarray."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VF3Cz1Zigtd"
   },
   "source": [
    "# Standardize the data\n",
    "### The RGB channel values are in the [0, 255] range. This is not ideal for a neural network; in general you should seek to make your input values small.\n",
    "\n",
    "### Here, you will standardize values to be in the [0, 1] range by using tf.keras.layers.Rescaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:34:19.123984Z",
     "iopub.status.busy": "2022-05-12T07:34:19.123641Z",
     "iopub.status.idle": "2022-05-12T07:34:19.144085Z",
     "shell.execute_reply": "2022-05-12T07:34:19.143328Z",
     "shell.execute_reply.started": "2022-05-12T07:34:19.12395Z"
    },
    "id": "2ptyYEfMigtd"
   },
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1EAOV9Zigtd"
   },
   "source": [
    "# Data augmentation\n",
    "### It takes the approach of generating additional training data from your existing examples by augmenting them using random transformations that yield believable-looking images. \n",
    "### This helps expose the model to more aspects of the data and generalize better.\n",
    "\n",
    "### You will implement data augmentation using the following Keras preprocessing layers: \n",
    "### **tf.keras.layers.RandomFlip**, **tf.keras.layers.RandomRotation**, and **tf.keras.layers.RandomZoom**. \n",
    "### These can be included inside your model like other layers, and run on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:37:25.769642Z",
     "iopub.status.busy": "2022-05-12T07:37:25.769106Z",
     "iopub.status.idle": "2022-05-12T07:37:25.882222Z",
     "shell.execute_reply": "2022-05-12T07:37:25.881579Z",
     "shell.execute_reply.started": "2022-05-12T07:37:25.769605Z"
    },
    "id": "cVQdLZmJigtd"
   },
   "outputs": [],
   "source": [
    "# add randomflip, randomrotation and randomzoom\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\", input_shape=(img_height,img_width,3)),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "263S8_bJigtd"
   },
   "source": [
    "# Building our ML Model\n",
    "## Now, you need to do some heavy lifting here. \n",
    "## For building our ML model, we will use tensorflow and keras, these libraries makes it very easy to apply ml with very little efforts\n",
    "\n",
    "### Note: The below image is extracted from some other source and it may not exactly represent our model, \n",
    "### but it will give you a nice idea of a Convolutional Neural Network, something that we will be using here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKO1WVLrigtd"
   },
   "source": [
    "![cnn-11.png](attachment:4cfeae39-c406-4949-87f2-0bc4c853022b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Vkz3wv8igte"
   },
   "source": [
    "## So, as we have seen above, for our (180 X 180 X 3) image, our first layer of neural network will contain 97,200 units in one Dense Layer. And multiplications of all the Dense layers with each other is a lot of computation for our lil computers.\n",
    "\n",
    "### That's where Convolutional layers comes into picture.\n",
    "\n",
    "### The following animation shows a convolutional layer consisting of 9 convolutional operations involving the 5x5 input matrix. Notice that each convolutional operation works on a different 3x3 slice of the input matrix. The resulting 3x3 matrix (on the right) consists of the results of the 9 convolutional operations:\n",
    "\n",
    "![](http://developers.google.com/machine-learning/glossary/images/AnimatedConvolution.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50pNlKFrigte"
   },
   "source": [
    "# Convolutional Neural Network\n",
    "## A neural network in which at least one layer is a convolutional layer. A typical convolutional neural network consists of some combination of the following layers:\n",
    "\n",
    "### convolutional layers\n",
    "### pooling layers\n",
    "### dense layers\n",
    "\n",
    "## Convolutional neural networks have had great success in certain kinds of problems, such as image recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBhAAHZ2igte"
   },
   "source": [
    "# Pooling\n",
    "\n",
    "![](http://developers.google.com/machine-learning/glossary/images/PoolingConvolution.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeV1oqWoigte"
   },
   "source": [
    "## Here are some components to enhance the performance of our model\n",
    "\n",
    "## Dropout - leave out some neurons at random!\n",
    "\n",
    "## BatchNormalization - [https://towardsdatascience.com/batch-norm-explained-visually-how-it-works-and-why-neural-networks-need-it-b18919692739](http://)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsWKFqSAigte"
   },
   "source": [
    "# Train a model\n",
    "## For completeness, you will show how to train a simple model using the datasets you have just prepared.\n",
    "\n",
    "## The Sequential model consists of three convolution blocks (tf.keras.layers.Conv2D) with a max pooling layer (tf.keras.layers.MaxPooling2D) in each of them. \n",
    "\n",
    "## There's a fully-connected layer (tf.keras.layers.Dense) with 128 units on top of it that is activated by a ReLU activation function ('relu')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:55:11.989382Z",
     "iopub.status.busy": "2022-05-12T07:55:11.989091Z",
     "iopub.status.idle": "2022-05-12T07:55:12.218855Z",
     "shell.execute_reply": "2022-05-12T07:55:12.217792Z",
     "shell.execute_reply.started": "2022-05-12T07:55:11.989351Z"
    },
    "id": "4RbyTeOmigte"
   },
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "# Sequential groups a linear stack of layers into a tf.keras.Model.\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    data_augmentation,\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D  \n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D  \n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6H1BKMyigte"
   },
   "source": [
    "## Choose the tf.keras.optimizers.Adam optimizer and tf.keras.losses.SparseCategoricalCrossentropy loss function. \n",
    "\n",
    "## To view training and validation accuracy for each training epoch, pass the metrics argument to Model.compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:55:41.555464Z",
     "iopub.status.busy": "2022-05-12T07:55:41.555197Z",
     "iopub.status.idle": "2022-05-12T07:55:41.570304Z",
     "shell.execute_reply": "2022-05-12T07:55:41.569609Z",
     "shell.execute_reply.started": "2022-05-12T07:55:41.555434Z"
    },
    "id": "RAAIau6eigte"
   },
   "outputs": [],
   "source": [
    "# Configures the model for training.\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHGYX14ligtf"
   },
   "source": [
    "## Note: You will only train for a few epochs so this tutorial runs quickly - or use GPU feature: Accelerator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:56:02.771342Z",
     "iopub.status.busy": "2022-05-12T07:56:02.77108Z",
     "iopub.status.idle": "2022-05-12T07:57:37.111113Z",
     "shell.execute_reply": "2022-05-12T07:57:37.110413Z",
     "shell.execute_reply.started": "2022-05-12T07:56:02.771311Z"
    },
    "id": "-gz0ojQFigtf"
   },
   "outputs": [],
   "source": [
    "# remember to turn on the GPU from notebook settings\n",
    "# if you don't see the Accelarator option on the right hand side, go to your kaggle profile and verify your profile by adding your mobile number\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=10\n",
    ")\n",
    "\n",
    "# it should take 30-40 seconds to train our model for first 3 epochs. And the val_accuracy should be around 0.46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fNNIF26igtf"
   },
   "source": [
    "## Note: You can also write a custom training loop instead of using Model.fit. \n",
    "## To learn more, visit the [Writing a training loop from scratch](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqwUKspRigtf"
   },
   "source": [
    "# Visualize training results\n",
    "## Create plots of loss and accuracy on the training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T07:57:55.75062Z",
     "iopub.status.busy": "2022-05-12T07:57:55.750359Z",
     "iopub.status.idle": "2022-05-12T07:57:56.024146Z",
     "shell.execute_reply": "2022-05-12T07:57:56.023457Z",
     "shell.execute_reply.started": "2022-05-12T07:57:55.750593Z"
    },
    "id": "8wlWZqAFigtf"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(10)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOQQyOt5igtf"
   },
   "source": [
    "# Next week you will get to learn -\n",
    "\n",
    "## Transfer Learning\n",
    "## Data Annotation\n",
    "## Handling Images with OpenCV"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "w4_s3_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
