{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kD6lbSNVLszk"
   },
   "source": [
    "# <center>Advanced ML pipeline with segmentation_models and Callbacks (W7S1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxcJ0zARmGOB"
   },
   "source": [
    "## **The most important thing to improve your model performance is to understand each and every step taken to build the final model.** \n",
    "\n",
    "*In this notebook, you will see how we increase our accuracy from 0.18 in previous lecture to 0.8 in this lecture.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHL8t-2oLszp"
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T07:01:55.754722Z",
     "iopub.status.busy": "2022-05-30T07:01:55.754299Z",
     "iopub.status.idle": "2022-05-30T07:02:03.316391Z",
     "shell.execute_reply": "2022-05-30T07:02:03.315561Z",
     "shell.execute_reply.started": "2022-05-30T07:01:55.754643Z"
    },
    "id": "3eItJm1hLszr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import math\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T07:02:19.716309Z",
     "iopub.status.busy": "2022-05-30T07:02:19.715658Z",
     "iopub.status.idle": "2022-05-30T07:02:20.409514Z",
     "shell.execute_reply": "2022-05-30T07:02:20.408678Z",
     "shell.execute_reply.started": "2022-05-30T07:02:19.716275Z"
    },
    "id": "ofv9tYqEkO5V"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Here load_data function is called. This will load the dataset paths and \n",
    "split it into X_train, X_test, y_train, y_test '''\n",
    "\n",
    "img_dir = '../input/artificial-lunar-rocky-landscape-dataset/images/render'\n",
    "mask_dir = '../input/artificial-lunar-rocky-landscape-dataset/images/clean'\n",
    "\n",
    "\n",
    "# let's get the list of image paths and mask paths in sorted order from the given directory respectively\n",
    "images = [os.path.join(img_dir, x) for x in sorted(os.listdir(img_dir))]\n",
    "masks = [os.path.join(mask_dir, x) for x in sorted(os.listdir(mask_dir))]\n",
    "\n",
    "\n",
    "# in this session, we will use our complete dataset\n",
    "X_train = images[:8000]\n",
    "y_train = masks[:8000]\n",
    "\n",
    "X_valid = images[8000:]\n",
    "y_valid = masks[8000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyRDdo0-kO5W"
   },
   "source": [
    "## Building Dataset generator from scratch using Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T07:02:23.883809Z",
     "iopub.status.busy": "2022-05-30T07:02:23.883468Z",
     "iopub.status.idle": "2022-05-30T07:02:23.897282Z",
     "shell.execute_reply": "2022-05-30T07:02:23.895731Z",
     "shell.execute_reply.started": "2022-05-30T07:02:23.883781Z"
    },
    "id": "8iibzosHkO5Y"
   },
   "outputs": [],
   "source": [
    "# Here, `x_set` is list of path to the images\n",
    "# and `y_set` are the associated classes.\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\n",
    "class LunarDataset(Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size, dims, classes):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.img_height, self.img_width = dims\n",
    "        self.classes = classes\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        count = 0\n",
    "        # https://numpy.org/doc/stable/reference/generated/numpy.zeros.html\n",
    "        xtr = np.zeros((self.batch_size, self.img_height, self.img_width, 3))\n",
    "        for filename in batch_x:\n",
    "            img = imread(filename)[:self.img_height, :self.img_width, :] / 255.0\n",
    "            img = img.astype(np.float32)\n",
    "            xtr[count] = img\n",
    "            count += 1\n",
    "            \n",
    "        count = 0\n",
    "        ytr = np.zeros((self.batch_size, self.img_height, self.img_width, num_classes))\n",
    "        for filename in batch_y:\n",
    "            mask = imread(filename, as_gray = True)[:self.img_height, :self.img_width] // 0.07\n",
    "            mask[mask == 3] = 2\n",
    "            mask[mask == 10] = 3\n",
    "            \n",
    "            # one hot encoding our masks using to_categorical\n",
    "            # https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical\n",
    "            mask = to_categorical(mask, num_classes = 4)\n",
    "            ytr[count] = mask\n",
    "            count += 1\n",
    "\n",
    "        return xtr, ytr.astype(np.int32)\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "dims = (480, 480)\n",
    "num_classes = 4\n",
    "\n",
    "train_dataset = LunarDataset(X_train, y_train, batch_size, dims, num_classes)\n",
    "valid_dataset = LunarDataset(X_valid, y_valid, batch_size, dims, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kk5QMvOYkO5a"
   },
   "source": [
    "## Let's visualize our masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T07:02:27.750357Z",
     "iopub.status.busy": "2022-05-30T07:02:27.749602Z",
     "iopub.status.idle": "2022-05-30T07:02:29.193657Z",
     "shell.execute_reply": "2022-05-30T07:02:29.192113Z",
     "shell.execute_reply.started": "2022-05-30T07:02:27.750323Z"
    },
    "id": "sz--yYp2kO5b"
   },
   "outputs": [],
   "source": [
    "sam = next(iter(train_dataset))\n",
    "\n",
    "sample = sam[1][1]\n",
    "\n",
    "i, v = np.unique(sample, return_counts = True)\n",
    "for a,b in zip(i,v):\n",
    "    print(a,\" \", b)\n",
    "    \n",
    "\n",
    "fig, (a1, a2, a3, a4) = plt.subplots(1, 4, figsize = (20, 5))\n",
    "\n",
    "a1.imshow(sample[:, :, 0])\n",
    "a2.imshow(sample[:, :, 1])\n",
    "a3.imshow(sample[:, :, 2])\n",
    "a4.imshow(sample[:, :, 3])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# four channels showing different classes\n",
    "# each channel have only 0 and 1 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZ3xM6nTZUNX"
   },
   "source": [
    "### Let's check out some basic steps of transfer learning using a pretrained model (VGG16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T07:02:35.999862Z",
     "iopub.status.busy": "2022-05-30T07:02:35.999058Z",
     "iopub.status.idle": "2022-05-30T07:02:39.654744Z",
     "shell.execute_reply": "2022-05-30T07:02:39.653899Z",
     "shell.execute_reply.started": "2022-05-30T07:02:35.999824Z"
    },
    "id": "4V04gfvYZu-q"
   },
   "outputs": [],
   "source": [
    "#### Step 1: Creating a base model \n",
    "\n",
    "IMG_SHAPE = (480, 480, 3)\n",
    "\n",
    "# include_top specify that we don't want to use the top layer (classifier)\n",
    "base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Step 2: Freezing the base\n",
    "\n",
    "# It is important to freeze the convolutional base before you compile and train the model.\n",
    "# Freezing prevents the weights in a given layer from being updated during training\n",
    "# VGG16 has many layers, so setting the entire model's trainable flag to False will freeze all of them.\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# Let's take a look at the base model architecture\n",
    "base_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "#### Step 3: Adding the head\n",
    "\n",
    "# inputs\n",
    "inputs = tf.keras.Input(shape=(480, 480, 3))\n",
    "\n",
    "# base with pretrained model\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# head layers\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(2)(x)\n",
    "\n",
    "# model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Let's take a look at the final model architecture\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# reference: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAqM5bf_s3QO"
   },
   "source": [
    "## segmentation_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khcnnP4asNE8"
   },
   "source": [
    "\n",
    "**segmentation_models** is a python library with Neural Networks for Image Segmentation based on Keras and TensorFlow.\n",
    "\n",
    "The main features of this library are:\n",
    "\n",
    "* High level API (just two lines of code to create model for segmentation)\n",
    "* 4 models architectures for binary and multi-class image segmentation (including legendary Unet)\n",
    "* 25 available backbones for each architecture\n",
    "* All backbones have pre-trained weights for faster and better convergence\n",
    "* Helpful segmentation losses (Jaccard, Dice, Focal) and metrics (IoU, F-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T07:02:56.515128Z",
     "iopub.status.busy": "2022-05-30T07:02:56.514188Z",
     "iopub.status.idle": "2022-05-30T07:03:08.795108Z",
     "shell.execute_reply": "2022-05-30T07:03:08.793940Z",
     "shell.execute_reply.started": "2022-05-30T07:02:56.515087Z"
    },
    "id": "TQ481azQsf2A"
   },
   "outputs": [],
   "source": [
    "# run this command to directly install the library in our notebook\n",
    "\n",
    "!pip install segmentation_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apuK6SQMsbhs"
   },
   "source": [
    "* Provide environment variable SM_FRAMEWORK=keras / SM_FRAMEWORK=tf.keras before import segmentation_models\n",
    "* Change framework sm.set_framework('keras') / sm.set_framework('tf.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T07:03:23.839466Z",
     "iopub.status.busy": "2022-05-30T07:03:23.838815Z",
     "iopub.status.idle": "2022-05-30T07:03:23.864619Z",
     "shell.execute_reply": "2022-05-30T07:03:23.863843Z",
     "shell.execute_reply.started": "2022-05-30T07:03:23.839430Z"
    },
    "id": "ckhpfcSNsXXG"
   },
   "outputs": [],
   "source": [
    "# By default it tries to import keras, if it is not installed, it will try to start with tensorflow.keras framework\n",
    "\n",
    "import segmentation_models as sm\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "sm.set_framework('tf.keras')\n",
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fdtf71zxkO5i"
   },
   "source": [
    "# Building our UNet model with segmentation_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T07:03:26.839173Z",
     "iopub.status.busy": "2022-05-30T07:03:26.838280Z",
     "iopub.status.idle": "2022-05-30T07:03:27.343329Z",
     "shell.execute_reply": "2022-05-30T07:03:27.341433Z",
     "shell.execute_reply.started": "2022-05-30T07:03:26.839121Z"
    },
    "id": "q9UGUpklLsz1"
   },
   "outputs": [],
   "source": [
    "BACKBONE = 'vgg16'\n",
    "input_shape = (480, 480, 3)\n",
    "n_classes = 4\n",
    "activation = 'softmax'\n",
    "\n",
    "# using segmentation_models to create U-net with vgg16 as a backbone\n",
    "# and pretrained imagenet weights\n",
    "\n",
    "# segmentation_model basically will create a mirror image of our backbone as expansion path and add to the contraction path\n",
    "model = sm.Unet(backbone_name = BACKBONE, \n",
    "                input_shape = input_shape, \n",
    "                classes = n_classes, \n",
    "                activation = activation,\n",
    "                encoder_weights = 'imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFpUjTLxLsz2"
   },
   "source": [
    "## Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T07:03:33.607686Z",
     "iopub.status.busy": "2022-05-30T07:03:33.607327Z",
     "iopub.status.idle": "2022-05-30T07:03:33.970893Z",
     "shell.execute_reply": "2022-05-30T07:03:33.969114Z",
     "shell.execute_reply.started": "2022-05-30T07:03:33.607655Z"
    },
    "id": "BAwylsJgLsz3"
   },
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters \"\"\"\n",
    "lr = 1e-4\n",
    "batch_size = 16\n",
    "epochs = 1\n",
    "\n",
    "# metrics for result validation\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "# compiling the model\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = tf.keras.optimizers.Adam(lr), \n",
    "              metrics = metrics)\n",
    "\n",
    "train_steps = len(X_train)//batch_size\n",
    "valid_steps = len(X_valid)//batch_size\n",
    "\n",
    "\n",
    "\"\"\" Callbacks \"\"\"\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=f'models/lunarModel_{current_datetime}.h5',\n",
    "                        monitor='val_iou_score', verbose=0, \n",
    "                        mode='max', save_best_model=False),\n",
    "             \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_iou_score\", mode='max', patience=4,\n",
    "                          factor=0.1, verbose=0, min_lr=1e-6),\n",
    "             \n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_iou_score\", patience=5, verbose=0, mode='max'),\n",
    "\n",
    "        tf.keras.callbacks.TensorBoard(f'models/logs_{current_datetime}')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhikbwebLsz3"
   },
   "source": [
    "\n",
    "model is compiled with **loss**=\"categorical_crossentropy\",  **optimizer**=Adam, **metrics**=iou_score\n",
    "\n",
    "**Callbacks** is a tool to customize the behavior of a Keras model during training, evaluation, or inference.\n",
    "\n",
    "**ModelCheckpoint:** used  to periodically save your model during training.\n",
    "\n",
    "**ReduceLROnPlateau:** Reduce learning rate when a metric has stopped improving.\n",
    "\n",
    "**EarlyStopping:** Stop training when a monitored metric has stopped improving.\n",
    "\n",
    "**TensorBoard:** Enable visualizations for TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPho7ynJLsz4"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T06:19:44.591679Z",
     "iopub.status.busy": "2022-05-30T06:19:44.591294Z",
     "iopub.status.idle": "2022-05-30T06:28:21.329890Z",
     "shell.execute_reply": "2022-05-30T06:28:21.328987Z",
     "shell.execute_reply.started": "2022-05-30T06:19:44.591648Z"
    },
    "id": "eK6nMaYkLsz4"
   },
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "model_history = model.fit(train_dataset,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_data=valid_dataset,\n",
    "        validation_steps=valid_steps,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "# val_iou_score is expected to reach almost 0.8 after 5 epochs even without using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BA1oCaDikO5l"
   },
   "source": [
    "Epoch 1/5\n",
    "500/500 [==============================] - 553s 1s/step - loss: 0.4765 - iou_score: 0.4762 - f1-score: 0.5403 - val_loss: 0.2147 - val_iou_score: 0.5423 - val_f1-score: 0.5970\n",
    "Epoch 2/5\n",
    "500/500 [==============================] - 508s 1s/step - loss: 0.1501 - iou_score: 0.6948 - f1-score: 0.7837 - val_loss: 0.1720 - val_iou_score: 0.6603 - val_f1-score: 0.7461\n",
    "Epoch 3/5\n",
    "500/500 [==============================] - 512s 1s/step - loss: 0.1204 - iou_score: 0.7489 - f1-score: 0.8338 - val_loss: 0.1116 - val_iou_score: 0.7383 - val_f1-score: 0.8242\n",
    "Epoch 4/5\n",
    "500/500 [==============================] - 508s 1s/step - loss: 0.1053 - iou_score: 0.7772 - f1-score: 0.8573 - val_loss: 0.1160 - val_iou_score: 0.7461 - val_f1-score: 0.8315\n",
    "Epoch 5/5\n",
    "500/500 [==============================] - 514s 1s/step - loss: 0.0989 - iou_score: 0.7877 - f1-score: 0.8656 - val_loss: 0.0906 - val_iou_score: 0.7976 - val_f1-score: 0.8726"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IobGiGA6Lsz4"
   },
   "source": [
    "## Predict from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T07:03:49.638692Z",
     "iopub.status.busy": "2022-05-30T07:03:49.638313Z",
     "iopub.status.idle": "2022-05-30T07:03:49.648953Z",
     "shell.execute_reply": "2022-05-30T07:03:49.647909Z",
     "shell.execute_reply.started": "2022-05-30T07:03:49.638660Z"
    },
    "id": "W-1_LmkTLsz5"
   },
   "outputs": [],
   "source": [
    "# function to predict result \n",
    "def predict_image(img_path, mask_path, model):\n",
    "    H = 480\n",
    "    W = 480\n",
    "    num_classes = 4\n",
    "\n",
    "    img = imread(img_path)\n",
    "    img = img[:480, :480, :]\n",
    "    img = img / 255.0\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    ## Read mask\n",
    "    mask = imread(mask_path, as_gray = True)\n",
    "    mask = mask[:480, :480]\n",
    "    \n",
    "    ## Prediction\n",
    "    pred_mask = model.predict(np.expand_dims(img, axis=0))\n",
    "    pred_mask = np.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[0]\n",
    "    \n",
    "    \n",
    "    # calculating IOU score\n",
    "    inter = np.logical_and(mask, pred_mask)\n",
    "    union = np.logical_or(mask, pred_mask)\n",
    "    \n",
    "    iou = inter.sum() / union.sum()\n",
    "\n",
    "    return img, mask, pred_mask, iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T07:03:52.656285Z",
     "iopub.status.busy": "2022-05-30T07:03:52.655890Z",
     "iopub.status.idle": "2022-05-30T07:04:03.777600Z",
     "shell.execute_reply": "2022-05-30T07:04:03.776040Z",
     "shell.execute_reply.started": "2022-05-30T07:03:52.656256Z"
    },
    "id": "314r8EbTLsz6"
   },
   "outputs": [],
   "source": [
    "img_path = '../input/artificial-lunar-rocky-landscape-dataset/images/render/render0042.png'\n",
    "mask_path = '../input/artificial-lunar-rocky-landscape-dataset/images/clean/clean0042.png'\n",
    "\n",
    "img, mask, pred_mask, iou = predict_image(img_path, mask_path, model)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (15, 10))\n",
    "\n",
    "ax1.set_title(\"Input Image\")\n",
    "ax1.imshow(img)\n",
    "\n",
    "ax2.set_title(\"True Mask\")\n",
    "ax2.imshow(mask, cmap = \"gray\")\n",
    "\n",
    "ax3.set_title(\"Predicted mask with IOU score %.2f\"%(iou))\n",
    "ax3.imshow(pred_mask, cmap = \"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgfn0B86kO5m"
   },
   "source": [
    "### You can see we have reached a satisfactory result for our project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we load a saved model in a new session and use it for predictions - WITHOUT TRAINING AGAIN?\n",
    "Yes, if we download it before shutting down our current kernel.\n",
    "\n",
    "On starting the new session, we can upload the saved model and use it for initializing weights of a newly created model instance!\n",
    "\n",
    "This is a new model 'variable' with optimized weights! - Kinda like our very own pretrained model :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T07:04:21.255691Z",
     "iopub.status.busy": "2022-05-30T07:04:21.255244Z",
     "iopub.status.idle": "2022-05-30T07:04:26.986831Z",
     "shell.execute_reply": "2022-05-30T07:04:26.986042Z",
     "shell.execute_reply.started": "2022-05-30T07:04:21.255646Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a new model instance\n",
    "new_model = sm.Unet(backbone_name = BACKBONE, \n",
    "                input_shape = input_shape, \n",
    "                classes = n_classes, \n",
    "                activation = activation,\n",
    "                encoder_weights = 'imagenet')\n",
    "\n",
    "# define the path to the checkpointed model after uploading it\n",
    "checkpoint_path = '../input/savedmodel1/lunarModel_20220530-061940.h5'\n",
    "\n",
    "#resolve dependencies - sometimes..\n",
    "dependencies = {\n",
    "    'iou_score': sm.metrics.IOUScore,\n",
    "    'f1-score': sm.metrics.FScore\n",
    "}\n",
    "\n",
    "# load the weights from the checkpoint\n",
    "new_model = keras.models.load_model(checkpoint_path, custom_objects=dependencies)\n",
    " \n",
    "# use loaded info for prediction\n",
    "img_path = '../input/artificial-lunar-rocky-landscape-dataset/images/render/render0028.png'\n",
    "mask_path = '../input/artificial-lunar-rocky-landscape-dataset/images/clean/clean0028.png'\n",
    "\n",
    "img, mask, pred_mask, iou = predict_image(img_path, mask_path, new_model)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (15, 10))\n",
    "\n",
    "ax1.set_title(\"Input Image\")\n",
    "ax1.imshow(img)\n",
    "\n",
    "ax2.set_title(\"True Mask\")\n",
    "ax2.imshow(mask, cmap = \"gray\")\n",
    "\n",
    "ax3.set_title(\"Predicted mask with IOU score %.2f\"%(iou))\n",
    "ax3.imshow(pred_mask, cmap = \"gray\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaMfFmCXkO5m"
   },
   "source": [
    "## In next lecture, you will learn some best practices to optimize your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ajAnaiZkO5m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q26M3dwpkO5n"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
