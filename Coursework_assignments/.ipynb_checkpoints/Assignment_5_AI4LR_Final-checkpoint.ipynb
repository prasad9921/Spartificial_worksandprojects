{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elcpXOswLRgc"
   },
   "source": [
    "# <center> Assignment 5 (AI4LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfmCfF7eiTpk"
   },
   "outputs": [],
   "source": [
    "Your_Name = \" \"\n",
    "Your_Email_id = \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juQiIIMl4qVz"
   },
   "source": [
    "## Open this notebook in kaggle for easy access to the dataset and related libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T06:41:52.762222Z",
     "iopub.status.busy": "2022-03-27T06:41:52.761932Z",
     "iopub.status.idle": "2022-03-27T06:41:52.767773Z",
     "shell.execute_reply": "2022-03-27T06:41:52.766709Z",
     "shell.execute_reply.started": "2022-03-27T06:41:52.762191Z"
    },
    "id": "f5ayJkkRwkjb"
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d72b-W8fFaKI"
   },
   "source": [
    "## Data \n",
    "\n",
    "To get the dataset for this assignment, got to Add data option and search for https://www.kaggle.com/datasets/datatangai/people-with-occlusion-and-multipose-face-data in Search URL field.\n",
    "\n",
    "Import this dataset and there is only one image in this dataset. We are going to use this image only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T06:39:31.674039Z",
     "iopub.status.busy": "2022-03-27T06:39:31.673784Z",
     "iopub.status.idle": "2022-03-27T06:39:33.209950Z",
     "shell.execute_reply": "2022-03-27T06:39:33.208877Z",
     "shell.execute_reply.started": "2022-03-27T06:39:31.673999Z"
    },
    "id": "T808--eV4qV0"
   },
   "outputs": [],
   "source": [
    "img_path = \"../input/people-with-occlusion-and-multipose-face-data/3.png\"\n",
    "\n",
    "img = Image.open(img_path)\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAhrBKqmjuHB"
   },
   "source": [
    "## Q1 (1 Point) \n",
    "\n",
    "Convert the images \"img\" into an array and store that array into 'img_arr' variable.\n",
    "\n",
    "Plot the img_arr using plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:01:23.807846Z",
     "iopub.status.busy": "2022-02-01T15:01:23.807293Z",
     "iopub.status.idle": "2022-02-01T15:01:24.294027Z",
     "shell.execute_reply": "2022-02-01T15:01:24.293337Z",
     "shell.execute_reply.started": "2022-02-01T15:01:23.807802Z"
    },
    "id": "ShSSOgg350kW"
   },
   "outputs": [],
   "source": [
    "# Complete the following code\n",
    "\n",
    "\n",
    "img_arr = \n",
    "\n",
    "\n",
    "# plot img_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqNymgaxpk1i"
   },
   "source": [
    "## Q2 (2 Points)\n",
    "Run the below code.\n",
    "\n",
    "Do you see anything abnormal with the shape of the above image? If yes, state the reason. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23zzRR39pj-X"
   },
   "outputs": [],
   "source": [
    "print(\"Image shape:\", img_arr.shape)\n",
    "\n",
    "## print your reason here\n",
    "\n",
    "reason = \"\"\n",
    "\n",
    "print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wj839JEq2vN"
   },
   "source": [
    "## Q3 (6 Points)\n",
    "The above image \"img_arr\" is a combination of ten different images, separate all ten images using numpy and show all of them using plt.subplot.\n",
    "\n",
    "(the size and shape of individual images should remain the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G979ANNupyoY"
   },
   "outputs": [],
   "source": [
    "# first we are converting our four channels image into three channels image (easy to use and no extra complexities)\n",
    "'''Do not make any change in this below line of code.'''\n",
    "img_arr = img_arr[:, :, :3]\n",
    "\n",
    "\n",
    "# Write your code here--------------------------->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYxLSwSWrgey"
   },
   "source": [
    "## Q4 (2 Points)\n",
    "imgGray = ** 0.2989 * R + 0.5870 * G + 0.1140 * B **. \n",
    "\n",
    "this is the formula to convert any colored images to greyscale. \n",
    "\n",
    "\n",
    "Convert \"first\" into greyscale using above formula and store it in \"first_bw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "482aUQZeraMd"
   },
   "outputs": [],
   "source": [
    "first = img_arr[:500, :290, :]\n",
    "\n",
    "plt.figure(figsize = (5,10))\n",
    "plt.imshow(first)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "## Write your code here\n",
    "\n",
    "first_bw = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiStl1oc6O5O"
   },
   "source": [
    "## Q5 (6 Points)\n",
    "Find out the effects of kernel1 and kernel2 on the \"first\" using cv2.filter2D function. \n",
    "\n",
    "Plot and State the difference between effect1 and effect2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbY77UkX67Xv"
   },
   "outputs": [],
   "source": [
    "kernel1 = np.array([[-1,-1,-1],\n",
    "                    [0,0,0],\n",
    "                    [1,1,1]])\n",
    "\n",
    "kernel2 = kernel1.transpose()\n",
    "\n",
    "\n",
    "effect1 = cv2.filter2D(src = first, kernel = kernel1, ddepth = -1)\n",
    "effect2 = cv2.filter2D(src = first, kernel = kernel2, ddepth = -1)\n",
    "\n",
    "# plot effect1 and effect2 using plt.subplots\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# state the difference\n",
    "\n",
    "difference = \"\"\n",
    "\n",
    "print(difference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qh-Tu3DrGf7Y"
   },
   "source": [
    "## Q6 (4 Points)\n",
    "\n",
    "State differences between -  \n",
    "\n",
    "> Feature extraction and finetuning in transfer learning.\n",
    "\n",
    "> Hidden layer in a neural network and Head layer in transfer learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T06:53:25.854647Z",
     "iopub.status.busy": "2022-03-27T06:53:25.854334Z",
     "iopub.status.idle": "2022-03-27T06:53:25.860818Z",
     "shell.execute_reply": "2022-03-27T06:53:25.859658Z",
     "shell.execute_reply.started": "2022-03-27T06:53:25.854591Z"
    },
    "id": "R1ja-IvR4d34"
   },
   "outputs": [],
   "source": [
    "# start your answer here\n",
    "\n",
    "answer1 = \n",
    "\n",
    "\n",
    "answer2 = \n",
    "\n",
    "print(answer1)\n",
    "print()\n",
    "print(answer2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7S2hsT-7eu-"
   },
   "source": [
    "## Q7 (1 point)\n",
    "\n",
    "Write the formula for IOU score using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qcETSSR8866"
   },
   "outputs": [],
   "source": [
    "# Print your answer \n",
    "\n",
    "formula ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UXaXUjhhCvz"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mL9NMduQFg5"
   },
   "source": [
    "## Q8 (3 points)\n",
    "\n",
    "For below model, \n",
    "\n",
    "For a Convolutional layer in neural network, below values are given\n",
    "\n",
    "> Input shape = (64, 64, 3)\n",
    "\n",
    "> Convolutional filter size = (3,3)\n",
    "\n",
    "> Number of Conv Filters = 16\n",
    "\n",
    "> padding = \"same\"\n",
    "\n",
    "> stride = 1\n",
    "\n",
    "\n",
    "Find out the **output shape** after this layer, **number of total trainable paramaters** and **computational cost**.\n",
    "\n",
    "Hint: Total trainable parameters is the sum of total number of weights and biases in the layer.\n",
    "\n",
    "Hint: Computational cost is the total number of matrix multiplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUVQCUDXP_Rm"
   },
   "outputs": [],
   "source": [
    "from keras.engine.sequential import Sequential\n",
    "from keras.layers import Input, Conv2D, Dense, MaxPooling2D, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "                    Input(shape = (500, 290, 3)),\n",
    "                    Conv2D(16, (3,3), activation = 'relu'),\n",
    "                    MaxPooling2D(2,2),\n",
    "                    Conv2D(32, (3,3), activation = 'relu'),\n",
    "                    MaxPooling2D(2,2),\n",
    "                    Conv2D(64, (3,3), activation = 'relu'),\n",
    "                    MaxPooling2D(2,2),\n",
    "                    Dense(256, activation = \"relu\"),\n",
    "                    Dropout(0.5),\n",
    "                    Dense(5, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "# write your answer here\n",
    "\n",
    "out_shape = \n",
    "\n",
    "train_params = \n",
    "\n",
    "comp_cost = # write a function for this looping over layers, calculating for each layer\n",
    "\n",
    "print(\"Output shape:\", out_shape)\n",
    "print(\"Trainable parameters:\", train_params)\n",
    "print(\"Computational Cost:\", comp_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gL2_7F2jxec"
   },
   "source": [
    "## Q9 (5 points)\n",
    "\n",
    "1. Write down the name of the model that used dropout for preventing overfitting for the first time?\n",
    "\n",
    "2. How did GoogleNet manage to reduce its number of parameters despite having a deep heirarchy of conv layers?\n",
    "\n",
    "3. Which network made 3-by-3 filters state-of-the-art?\n",
    "\n",
    "4. How does VGGNet ensure growing depth despit shrinking spatial dimensions deep into the network hierarchy?\n",
    "\n",
    "5. What does Deconvnet do? Which network introduced it? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJMt9xKSTQsf"
   },
   "source": [
    "## Q10 (20 points)\n",
    "\n",
    "Use the Iris dataset to classify iris flowers into three classes of species.\n",
    "https://www.kaggle.com/datasets/uciml/iris \n",
    "\n",
    "Develop a transfer learning network by following these steps:\n",
    "1. Derive a base model using VGGNet - any configuration of your choice. \n",
    "\n",
    "2. Augment your data set by defining data augmentation layers - use at least 2 different augmentation techniques.\n",
    "\n",
    "3. Build your network with the augmentation layers and the base model from VGGNet.\n",
    "\n",
    "4. Add a pooling layer and a dense layer at the end to get a single prediction per image.\n",
    "\n",
    "5. Compile your model using categorical cross entropy loss, adam optimizer, and accuracy metric.\n",
    "\n",
    "6. Train your network twice - once with dropout and another time without dropout. \n",
    "\n",
    "7. Plot training and validation losses and accuracies for both cases of point #6. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIiqmkDHRLwC"
   },
   "source": [
    "## Thank you for completing all the questions!\n",
    "#### Download your notebook and submit it in the google form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whmuWZ5AlMzL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment_5_AI4LR_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
