{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### IMPORTANT ########\n",
    "Your_Name = \"V N D S R Prasad Jettiboina\"\n",
    "Your_Email_id = \"prasadjv99@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-08T18:05:16.621776Z",
     "iopub.status.busy": "2022-05-08T18:05:16.621388Z",
     "iopub.status.idle": "2022-05-08T18:05:16.857328Z",
     "shell.execute_reply": "2022-05-08T18:05:16.856449Z",
     "shell.execute_reply.started": "2022-05-08T18:05:16.621678Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 (3 points) \n",
    "#### Which of the following is not an activation function\n",
    "\n",
    "* a - Sigmoid function\n",
    "* b - Hyperbolic tangent function\n",
    "* c - Rectified linear unit (RELU) function\n",
    "* d - Leaky RELU function\n",
    "* e - dynamic function\n",
    "* f - Maxout function\n",
    "* g - gaussian function\n",
    "* h - sobel function\n",
    "* i - Exponential Linear unit (ELU) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T18:05:20.515375Z",
     "iopub.status.busy": "2022-05-08T18:05:20.515071Z",
     "iopub.status.idle": "2022-05-08T18:05:20.521280Z",
     "shell.execute_reply": "2022-05-08T18:05:20.520637Z",
     "shell.execute_reply.started": "2022-05-08T18:05:20.515345Z"
    }
   },
   "outputs": [],
   "source": [
    "# print the correct options here\n",
    "print(\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2(3 points)\n",
    "\n",
    "#### Suppose a neuron N in layer 2 has 5 input neurons from layer 1. Do all these 5 input neurons have the same contribution towards the output of the neuron N? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T18:05:37.531824Z",
     "iopub.status.busy": "2022-05-08T18:05:37.531244Z",
     "iopub.status.idle": "2022-05-08T18:05:37.536091Z",
     "shell.execute_reply": "2022-05-08T18:05:37.535423Z",
     "shell.execute_reply.started": "2022-05-08T18:05:37.531785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definitely No. The reason is every neuron has different weights associated with it. The contribution of every neuron depends on the weights.\n",
      "But all these 5 input neurons have SOME contribution towards the output of the neuron N\n"
     ]
    }
   ],
   "source": [
    "# write your answer here \n",
    "print(\"Definitely No. The reason is every neuron has different weights associated with it. The contribution of every neuron depends on the weights.\\nBut all these 5 input neurons have SOME contribution towards the output of the neuron N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 (4 points)\n",
    "#### Organise below points in right sequence\n",
    "\n",
    "1. Dataset capturing \n",
    "2. Optimizing parameters with backpropagation\n",
    "3. Predicting the final output using our model\n",
    "4. Data preprocessing\n",
    "5. Calculating loss function\n",
    "6. Applying activation function on initial output\n",
    "7. Initializing weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T18:05:50.662944Z",
     "iopub.status.busy": "2022-05-08T18:05:50.662349Z",
     "iopub.status.idle": "2022-05-08T18:05:50.666568Z",
     "shell.execute_reply": "2022-05-08T18:05:50.666034Z",
     "shell.execute_reply.started": "2022-05-08T18:05:50.662905Z"
    }
   },
   "outputs": [],
   "source": [
    "# print the right sequence here\n",
    "print(\"1,4,7,6,5,2,3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 (6 points) \n",
    "\n",
    "#### Define below points - \n",
    "\n",
    "a. Why is normalization done in batches? \n",
    "\n",
    "b. When is it suitable to use batches? \n",
    "\n",
    "c. Can we do without batches? If yes, in which case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T18:06:05.277264Z",
     "iopub.status.busy": "2022-05-08T18:06:05.276922Z",
     "iopub.status.idle": "2022-05-08T18:06:05.285521Z",
     "shell.execute_reply": "2022-05-08T18:06:05.284603Z",
     "shell.execute_reply.started": "2022-05-08T18:06:05.277230Z"
    }
   },
   "outputs": [],
   "source": [
    "# write you answers here\n",
    "\n",
    "a = \"Batch normalization solves a major problem called internal covariate shift. It helps by making the data flowing between intermediate layers of the neural network, with which one can use a higher learning rate.\\nIt has a regularizing effect which means you can often remove dropout which we generally apply.\"\n",
    "b = \"Batch processing is most often used when dealing with very large amounts of data, and/or when data sources are legacy systems that are not capable of delivering data in streams.\\nSo, In general if we have very huge amount of data we can go for batches it is recommended.\"\n",
    "c = \"Yes, we can normalize without batches thorugh adaptation of training process. In the case of transfer learning\"\n",
    "\n",
    "print(a)\n",
    "print()\n",
    "print(b)\n",
    "print()\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5  (4 points)\n",
    "\n",
    "#### Which propogation pass helps you (forward, backward)\n",
    "\n",
    "a. obtain network output?\n",
    "\n",
    "b. update weights?\n",
    "\n",
    "c. calculate gradients?\n",
    "\n",
    "d. calculate loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T18:06:17.012612Z",
     "iopub.status.busy": "2022-05-08T18:06:17.012020Z",
     "iopub.status.idle": "2022-05-08T18:06:17.018650Z",
     "shell.execute_reply": "2022-05-08T18:06:17.017906Z",
     "shell.execute_reply.started": "2022-05-08T18:06:17.012570Z"
    }
   },
   "outputs": [],
   "source": [
    "# print your answers below\n",
    "\n",
    "print('forward')\n",
    "\n",
    "print('backward')\n",
    "\n",
    "print('backward')\n",
    "\n",
    "print('forward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. (4 points)\n",
    "### Write categorical crossentropy loss in python from scratch and state a difference between categorial crossentropy and binary crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T18:23:27.552764Z",
     "iopub.status.busy": "2022-05-08T18:23:27.552382Z",
     "iopub.status.idle": "2022-05-08T18:23:27.560124Z",
     "shell.execute_reply": "2022-05-08T18:23:27.559435Z",
     "shell.execute_reply.started": "2022-05-08T18:23:27.552729Z"
    }
   },
   "outputs": [],
   "source": [
    "## write your answers here\n",
    "def SoftMax(x):\n",
    "    x = np.insert(x, x.shape[1], 0, axis=1)\n",
    "    x -= np.max(x)\n",
    "    return softmax(x, axis=1)\n",
    "\n",
    "def categorical_cross_entropy(W, X, y, epsilon=1e-10):\n",
    "    ypred  = SoftMax(X @ W)\n",
    "    return -np.mean(y * np.log(ypred + epsilon))\n",
    "\n",
    "\n",
    "print(\"Categorical and Binary Crossentropy both are loss functions used for Classification problem\\nBinary is for 2 class problem\\nCategorical is for k class (multi class) problem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a pokemon classification model using tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset\n",
    "\n",
    "#### Go to Add data button and import https://www.kaggle.com/datasets/vishalsubbiah/pokemon-images-and-types dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.7 (5 points)\n",
    "#### List all the image filenames present in \"../input/pokemon-images-and-types/images/images\" location and show first five images using matplotib subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T18:06:47.099125Z",
     "iopub.status.busy": "2022-05-08T18:06:47.098789Z",
     "iopub.status.idle": "2022-05-08T18:06:48.129460Z",
     "shell.execute_reply": "2022-05-08T18:06:48.128764Z",
     "shell.execute_reply.started": "2022-05-08T18:06:47.099090Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "# defining root directory\n",
    "root_dir = \"../input/pokemon-images-and-types/images/images\"\n",
    "\n",
    "files = os.listdir(root_dir)\n",
    "\n",
    "print(files)\n",
    "\n",
    "# plot here\n",
    "f,ax=plt.subplots(5,figsize=(40,40))\n",
    "for i in range(5):\n",
    "    im=cv2.imread(os.path.join(root_dir,files[i]))\n",
    "    ax[i].imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the below 3 cells as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T18:07:03.200128Z",
     "iopub.status.busy": "2022-05-08T18:07:03.199226Z",
     "iopub.status.idle": "2022-05-08T18:07:03.226607Z",
     "shell.execute_reply": "2022-05-08T18:07:03.225818Z",
     "shell.execute_reply.started": "2022-05-08T18:07:03.200074Z"
    }
   },
   "outputs": [],
   "source": [
    "## Run the below cells as it is\n",
    "data = pd.read_csv(\"../input/pokemon-images-and-types/pokemon.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are going to use Type1 column as our labels. Each Name is unique and classified into 18 Type1 types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T18:07:08.440373Z",
     "iopub.status.busy": "2022-05-08T18:07:08.439835Z",
     "iopub.status.idle": "2022-05-08T18:07:08.451140Z",
     "shell.execute_reply": "2022-05-08T18:07:08.450268Z",
     "shell.execute_reply.started": "2022-05-08T18:07:08.440327Z"
    }
   },
   "outputs": [],
   "source": [
    "## Run the below cells as it is\n",
    "data_dict = {}\n",
    "\n",
    "for key, val in zip(data[\"Name\"], data[\"Type1\"]):\n",
    "    data_dict[key] = val\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T18:07:13.386759Z",
     "iopub.status.busy": "2022-05-08T18:07:13.386482Z",
     "iopub.status.idle": "2022-05-08T18:07:13.394778Z",
     "shell.execute_reply": "2022-05-08T18:07:13.393951Z",
     "shell.execute_reply.started": "2022-05-08T18:07:13.386729Z"
    }
   },
   "outputs": [],
   "source": [
    "## Run the below cells as it is\n",
    "labels = data[\"Type1\"].unique()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8. (7 points)\n",
    "\n",
    "#### Create a dictionary and assign each label in labels list a unique id from 1 to 18. Name the dictionary as \"labels_idx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-05-08T18:11:46.826871Z",
     "iopub.status.busy": "2022-05-08T18:11:46.826354Z",
     "iopub.status.idle": "2022-05-08T18:11:46.833523Z",
     "shell.execute_reply": "2022-05-08T18:11:46.832532Z",
     "shell.execute_reply.started": "2022-05-08T18:11:46.826805Z"
    }
   },
   "outputs": [],
   "source": [
    "## write your code here\n",
    "\n",
    "labels_idx = {}\n",
    "labels_dict = {}\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    labels_idx[labels[i]]=i\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    labels_dict[i]=labels[i]\n",
    "\n",
    "print(labels_idx)\n",
    "#print()\n",
    "#print(labels_dict)\n",
    "\n",
    "#In label_idx  key:label val:id\n",
    "#In label_dict key:id    val:label\n",
    "\n",
    "#if we want to see ids of lables we can for label_idx ----------- label_idx['Water']->3\n",
    "#if we want to call/get labels using ids we go for label_dict --- label_dict[2]->'Fire'\n",
    "\n",
    "#nothing just key:value <->\n",
    "#We are using labels_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.9 (4 points)\n",
    "#### Understand and Complete the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T18:11:49.710301Z",
     "iopub.status.busy": "2022-05-08T18:11:49.709993Z",
     "iopub.status.idle": "2022-05-08T18:11:50.758777Z",
     "shell.execute_reply": "2022-05-08T18:11:50.757794Z",
     "shell.execute_reply.started": "2022-05-08T18:11:49.710265Z"
    }
   },
   "outputs": [],
   "source": [
    "final_images = []\n",
    "final_labels = []\n",
    "# count = 0\n",
    "for file in files:\n",
    "    # pass an argument in place of \"arg\" in below line so that we can read image as grayscale\n",
    "    img = cv2.imread(os.path.join(root_dir, file), 0) #cv2.IMREAD_GRAYSCALE: It specifies to load an image in grayscale mode. Alternatively, we can pass integer value 0 for this flag.\n",
    "    label = labels_idx[data_dict[file.split(\".\")[0]]] # read this line atleast four times for better understanding\n",
    "    \n",
    "    # append img in final_images list\n",
    "    final_images.append(img)\n",
    "    # append label in final_labels list\n",
    "    final_labels.append(label)\n",
    "    \n",
    "    \n",
    "# converting lists into numpy arrayn\n",
    "# normalizing and reshaping the data (do not make any change)\n",
    "final_images = np.array(final_images, dtype = np.float32)/255.0\n",
    "final_labels = np.array(final_labels, dtype = np.int8).reshape(809, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have segregated our data into images and labels and is the time to build our model using tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.10 (10 points)\n",
    "\n",
    "#### Complete the following code to create a 1 input, 3 layer fully connected and an output layer network to provide final output of 18 classes. \n",
    "\n",
    "NOTE: Use suitable activation functions, number of neurons and try to keep the trainbale parameters below 1 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T18:11:54.013755Z",
     "iopub.status.busy": "2022-05-08T18:11:54.012439Z",
     "iopub.status.idle": "2022-05-08T18:11:54.072921Z",
     "shell.execute_reply": "2022-05-08T18:11:54.071949Z",
     "shell.execute_reply.started": "2022-05-08T18:11:54.013685Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(120, 120)),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dense(18)\n",
    "])\n",
    "# print model summary and check trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T18:12:00.070012Z",
     "iopub.status.busy": "2022-05-08T18:12:00.069183Z",
     "iopub.status.idle": "2022-05-08T18:12:07.155044Z",
     "shell.execute_reply": "2022-05-08T18:12:07.154246Z",
     "shell.execute_reply.started": "2022-05-08T18:12:00.069970Z"
    }
   },
   "outputs": [],
   "source": [
    "# compile model (Use: Adam optimizer, categorical_crossentropy loss and metrics as Accuracy)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "''' Fit model for training for 50 epochs (make sure to turn your notebook's GPU Accelerator on from settings given on the right hand side)\n",
    "If you do not see Accelarator and Internet options in Setting then please verify your kaggle profile using your phone number '''\n",
    "# fit model (use images and labels)\n",
    "\n",
    "history = model.fit(final_images, final_labels, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T18:12:17.183907Z",
     "iopub.status.busy": "2022-05-08T18:12:17.183578Z",
     "iopub.status.idle": "2022-05-08T18:12:17.404445Z",
     "shell.execute_reply": "2022-05-08T18:12:17.402792Z",
     "shell.execute_reply.started": "2022-05-08T18:12:17.183875Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict the class of any image using our trained model\n",
    "\n",
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(final_images)\n",
    "\n",
    "print(\"\\n\",predictions[0])\n",
    "id = np.argmax(predictions[0])\n",
    "print(\"\\nid that we got from the model as prediction: {}\\nType of pokemon associted with that id: {} \".format(id,labels[id]))\n",
    "print(\"accuracy of the model\",history.history['accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://docs.google.com/forms/u/3/d/e/1FAIpQLSeXqkWjhbC7nDM1eRGnqbZaRJrJjlRp-76LZBUIYDmrRFtw3A/formResponse?pli=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
